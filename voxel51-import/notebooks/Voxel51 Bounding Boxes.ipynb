{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip3 uninstall -y opencv-contrib-python opencv-python\n",
    "! pip3 uninstall -y opencv-python\n",
    "\n",
    "! pip3 install imutils opencv-contrib-python\n",
    "! apt install -y libgl1-mesa-glx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! apt -y remove python-opencv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "import fiftyone as fo\n",
    "import os\n",
    "# import the necessary packages\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "#from tensorflow.keras.applications.resnet import preprocess_input\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "from tensorflow.keras.applications import imagenet_utils\n",
    "from imutils.object_detection import non_max_suppression\n",
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import imutils\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "file_path = \"/tf/testing\"\n",
    "\n",
    "model_path = '/tf/dataset/plane-detector'\n",
    "INPUT_SIZE = (299, 299)\n",
    "MIN_CONF = 1\n",
    "FAST = True\n",
    "batch_size = 1000\n",
    "# Create the dataset\n",
    "try:\n",
    "    dataset = fo.load_dataset(\"plane-dataset\")\n",
    "except fo.core.dataset.DoesNotExistError:\n",
    "    dataset = fo.Dataset(name=\"plane-dataset\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load our network weights from disk\n",
    "print(\"[INFO] loading network...\")\n",
    "# load the trained model\n",
    "model = load_model(model_path)\n",
    "model.compile(\n",
    "    optimizer=keras.optimizers.Adam(1e-5),  # Low learning rate\n",
    "    loss=keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "    metrics=[keras.metrics.BinaryAccuracy()],\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def selective_search(image, fast):\n",
    "\t# initialize OpenCV's selective search implementation and set the\n",
    "\t# input image\n",
    "\tss = cv2.ximgproc.segmentation.createSelectiveSearchSegmentation()\n",
    "\tss.setBaseImage(image)\n",
    "\t# check to see if we are using the *fast* but *less accurate* version\n",
    "\t# of selective search\n",
    "\tif fast:\n",
    "\t\tss.switchToSelectiveSearchFast()\n",
    "\t# otherwise we are using the *slower* but *more accurate* version\n",
    "\telse:\n",
    "\t\tss.switchToSelectiveSearchQuality()\n",
    "\t# run selective search on the input image\n",
    "\trects = ss.process()\n",
    "\t# return the region proposal bounding boxes\n",
    "\treturn rects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def findPlane(file_path):\n",
    "    # load the input image\n",
    "    image = cv2.imread(file_path)\n",
    "    (H, W) = image.shape[:2]\n",
    "    rects = selective_search(image, True)\n",
    "    print(\"[INFO] {} regions found by selective search\".format(len(rects)))\n",
    "    # initialize the list of region proposals that we'll be classifying\n",
    "    # along with their associated bounding boxes\n",
    "    \n",
    "    proposals = []\n",
    "    boxes = []\n",
    "    # loop over the region proposal bounding box coordinates generated by\n",
    "    # running selective search\n",
    "    for (x, y, w, h) in rects:\n",
    "        # if the width or height of the region is less than 10% of the\n",
    "        # image width or height, ignore it (i.e., filter out small\n",
    "        # objects that are likely false-positives)\n",
    "        if w / float(W) > 0.2 or h / float(H) > 0.2:\n",
    "            continue\n",
    "        #if w / float(W) < 0.05 or h / float(H) < 0.05:\n",
    "        #    continue\n",
    "        # extract the region from the input image, convert it from BGR to\n",
    "        # RGB channel ordering, and then resize it to 224x224 (the input\n",
    "        # dimensions required by our pre-trained CNN)\n",
    "\n",
    "\n",
    "        roi = image[y:y + h, x:x + w]\n",
    "\n",
    "        # Crop, but add a border\n",
    "        old_size = roi.shape[:2]\n",
    "        ratio = float(299)/max(old_size)\n",
    "        new_size = tuple([int(x*ratio) for x in old_size])\n",
    "        roi = cv2.resize(roi, (new_size[1], new_size[0]))\n",
    "\n",
    "        delta_w = 398 - new_size[1] # this gets us back to the original image ratio size from taining\n",
    "        delta_h = 299 - new_size[0]\n",
    "        top, bottom = delta_h//2, delta_h-(delta_h//2)\n",
    "        left, right = delta_w//2, delta_w-(delta_w//2)\n",
    "\n",
    "        color = [0, 0, 0]\n",
    "        roi = cv2.copyMakeBorder(roi, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n",
    "\n",
    "        roi = cv2.resize(roi, (299, 299))\n",
    "\n",
    "        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "        roi = img_to_array(roi)\n",
    "        #roi = preprocess_input(roi)\n",
    "        # update our proposals and bounding boxes lists\n",
    "        proposals.append(roi)\n",
    "        boxes.append((x, y, w, h))\n",
    "\n",
    "    print(\"[INFO] {} boxes to invesitgate\".format(len(boxes)))\n",
    "    print(\"[INFO] {} proposals to predict\".format(len(boxes)))\n",
    "    \n",
    "    # convert the proposals list into NumPy array and show its dimensions\n",
    "    proposals = np.array(proposals, dtype=\"float32\")\n",
    "    print(\"[INFO] proposal shape: {}\".format(proposals.shape))\n",
    "    # classify each of the proposal ROIs using ResNet and then decode the\n",
    "    # predictions\n",
    "    print(\"[INFO] classifying proposals...\")\n",
    "    preds = model.predict(proposals)\n",
    "    \n",
    "    print(\"[INFO] {} predictions\".format(len(preds)))\n",
    "    labels = {\"plane\":[]}\n",
    "    for (i, p) in enumerate(preds):\n",
    "        # grab the prediction information for the current ROI\n",
    "        #(imagenetID, label, prob) = p[0]\n",
    "        prob = p[0]\n",
    "        # filter out weak detections by ensuring the predicted probability\n",
    "        # is greater than the minimum probability\n",
    "        if prob >= MIN_CONF:\n",
    "            # grab the bounding box associated with the prediction and\n",
    "            # convert the coordinates\n",
    "            (x, y, w, h) = boxes[i]\n",
    "            box = (x, y, x + w, y + h)\n",
    "            #print(box)\n",
    "            # grab the list of predictions for the label and add the\n",
    "            # bounding box + probability to the list\n",
    "            #L = labels.get(\"plane\",[])\n",
    "            #L.append((box, prob))\n",
    "            labels[\"plane\"].append((box, prob))\n",
    "\n",
    "\n",
    "    print(\"[INFO] {} predicted values\".format(len(labels[\"plane\"])))\n",
    "    \n",
    "    label=\"plane\"\n",
    "    # clone the original image so that we can draw on it\n",
    "    print(\"[INFO] showing results for '{}'\".format(label))\n",
    "    \n",
    "    # extract the bounding boxes and associated prediction\n",
    "    # probabilities, then apply non-maxima suppression\n",
    "    boxes = np.array([p[0] for p in labels[label]])\n",
    "    proba = np.array([p[1] for p in labels[label]])\n",
    "    if len(proba) > 0:\n",
    "        idx = np.argmax(proba)\n",
    "        maxBox=boxes[idx]\n",
    "        (startX, startY, endX, endY) = maxBox\n",
    "        x = startX\n",
    "        y = startY\n",
    "        w = endX - startX\n",
    "        h = endY - startY\n",
    "        floatX = x / W\n",
    "        floatY = y / H\n",
    "        floatW = w / W\n",
    "        floatH = h / H\n",
    "        return [floatX,floatY,floatW,floatH]\n",
    "    else:\n",
    "        return None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset, auto=False)\n",
    "dataset.exists(\"plane\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = dataset.skipped_view = dataset.match({\"plane_spot\": {\"$exists\": False, \"$eq\": None}}).match_tags(\"plane\").shuffle()\n",
    "for sample in view:\n",
    "    box = findPlane(sample.filepath)\n",
    "    if box != None:\n",
    "        detections = []\n",
    "\n",
    "\n",
    "\n",
    "        detections.append(fo.Detection(label=\"plane\", bounding_box=box))\n",
    "\n",
    "        # Store detections in a field name of your choice\n",
    "        sample[\"plane_spot\"] = fo.Detections(detections=detections)\n",
    "        sample.save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset, auto=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "view = dataset.exists(\"plane_spot\")\n",
    "session.view = view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a view containing only the selected samples\n",
    "selected_view = dataset.select(session.selected)\n",
    "\n",
    "for sample in selected_view:\n",
    "    sample.tags.append(\"relabel\")\n",
    "    sample.save()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}