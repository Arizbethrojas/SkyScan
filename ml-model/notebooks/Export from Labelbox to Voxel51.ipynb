{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export from Labelbox to Voxel51\n",
    "After you have finished labeling data in LabelBox, this notebook lets you import the labels back into a Voxel51 Dataset.\n",
    "In the Labelbox web UI, export the project and download the JSON file. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "LABELBOX_EXPORT_JSON = \"/tf/media/export-2021-05-20T13_18_09.947Z.json\"\n",
    "#labelboxExportJson =  \"/tf/notebooks/export-2021-02-01T01-34-34.538Z.json\" # Download the exported JSON and update this\n",
    "DATASET_NAME = \"jsm-test-dataset\"\n",
    "#dataset_name = \"test-dataset\" # The name of the V51 Dataset to use\n",
    "LABELBOX_ID_FIELD = \"labelbox_id\"\n",
    "#labelbox_id_field = \"labelbox_id\" # V51 Sample field where the corresponding Labelbox ID was save when it was uploaded to Labelbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Utilities for working with annotations in\n",
    "`Labelbox format <https://labelbox.com/docs/exporting-data/export-format-detail>`_.\n",
    "\n",
    "| Copyright 2017-2021, Voxel51, Inc.\n",
    "| `voxel51.com <https://voxel51.com/>`_\n",
    "|\n",
    "\"\"\"\n",
    "from copy import copy\n",
    "import logging\n",
    "import os\n",
    "from uuid import uuid4\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import eta.core.image as etai\n",
    "import eta.core.serial as etas\n",
    "import eta.core.utils as etau\n",
    "import eta.core.web as etaw\n",
    "\n",
    "import fiftyone.core.collections as foc\n",
    "import fiftyone.core.fields as fof\n",
    "import fiftyone.core.labels as fol\n",
    "import fiftyone.core.media as fomm\n",
    "import fiftyone.core.metadata as fom\n",
    "import fiftyone.core.sample as fos\n",
    "import fiftyone.core.utils as fou\n",
    "\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "#\n",
    "# @todo\n",
    "#   Must add support add support for populating `schemaId` when exporting\n",
    "#   labels in order for model-assisted labeling to work properly\n",
    "#\n",
    "#   cf https://labelbox.com/docs/automation/model-assisted-labeling\n",
    "#\n",
    "\n",
    "\n",
    "def custom_import_from_labelbox(\n",
    "    dataset,\n",
    "    json_path,\n",
    "    label_prefix=None,\n",
    "    download_dir=None,\n",
    "    labelbox_id_field=\"labelbox_id\",\n",
    "):\n",
    "    \"\"\"Imports the labels from the Labelbox project into the FiftyOne dataset.\n",
    "\n",
    "    The ``labelbox_id_field`` of the FiftyOne samples are used to associate the\n",
    "    corresponding Labelbox labels.\n",
    "\n",
    "    If a ``download_dir`` is provided, any Labelbox IDs with no matching\n",
    "    FiftyOne sample are added to the FiftyOne dataset, and their media is\n",
    "    downloaded into ``download_dir``.\n",
    "\n",
    "    The provided ``json_path`` should contain a JSON file in the following\n",
    "    format::\n",
    "\n",
    "        [\n",
    "            {\n",
    "                \"ID\": <labelbox-id>,\n",
    "                \"Labeled Data\": <url-or-None>,\n",
    "                \"Label\": {...}\n",
    "            }\n",
    "        ]\n",
    "\n",
    "    When importing image labels, the ``Label`` field should contain a dict of\n",
    "    `Labelbox image labels <https://labelbox.com/docs/exporting-data/export-format-detail#images>`_::\n",
    "\n",
    "        {\n",
    "            \"objects\": [...],\n",
    "            \"classifications\": [...]\n",
    "        }\n",
    "\n",
    "    When importing video labels, the ``Label`` field should contain a dict as\n",
    "    follows::\n",
    "\n",
    "        {\n",
    "            \"frames\": <url-or-filepath>\n",
    "        }\n",
    "\n",
    "    where the ``frames`` field can either contain a URL, in which case the\n",
    "    file is downloaded from the web, or the path to NDJSON file on disk of\n",
    "    `Labelbox video labels <https://labelbox.com/docs/exporting-data/export-format-detail#video>`_::\n",
    "\n",
    "        {\"frameNumber\": 1, \"objects\": [...], \"classifications\": [...]}\n",
    "        {\"frameNumber\": 2, \"objects\": [...], \"classifications\": [...]}\n",
    "        ...\n",
    "\n",
    "    Args:\n",
    "        dataset: a :class:`fiftyone.core.dataset.Dataset`\n",
    "        json_path: the path to the Labelbox JSON export to load\n",
    "        labelbox_project_or_json_path: a ``labelbox.schema.project.Project`` or\n",
    "            the path to the JSON export of a Labelbox project on disk\n",
    "        label_prefix (None): a prefix to prepend to the sample label field(s)\n",
    "            that are created, separated by an underscore\n",
    "        download_dir (None): a directory into which to download the media for\n",
    "            any Labelbox IDs with no corresponding sample with the matching\n",
    "            ``labelbox_id_field`` value. This can be omitted if all IDs are\n",
    "            already present or you do not wish to download media and add new\n",
    "            samples\n",
    "        labelbox_id_field (\"labelbox_id\"): the sample field to lookup/store the\n",
    "            IDs of the Labelbox DataRows\n",
    "    \"\"\"\n",
    "    if download_dir:\n",
    "        filename_maker = fou.UniqueFilenameMaker(output_dir=download_dir)\n",
    "\n",
    "    if labelbox_id_field not in dataset.get_field_schema():\n",
    "        dataset.add_sample_field(labelbox_id_field, fof.StringField)\n",
    "\n",
    "    id_map = {}\n",
    "    for sample in dataset.select_fields(labelbox_id_field):\n",
    "        id_map[sample[labelbox_id_field]] = sample.id\n",
    "\n",
    "    if label_prefix:\n",
    "        label_key = lambda k: label_prefix + \"_\" + k\n",
    "    else:\n",
    "        label_key = lambda k: k\n",
    "\n",
    "    is_video = dataset.media_type == fomm.VIDEO\n",
    "\n",
    "    # Load labels\n",
    "    d_list = etas.read_json(json_path)\n",
    "\n",
    "    # ref: https://github.com/Labelbox/labelbox/blob/7c79b76310fa867dd38077e83a0852a259564da1/exporters/coco-exporter/coco_exporter.py#L33\n",
    "    with fou.ProgressBar() as pb:\n",
    "        for d in pb(d_list):\n",
    "            labelbox_id = d[\"DataRow ID\"]\n",
    "\n",
    "            if labelbox_id in id_map:\n",
    "                # Get existing sample\n",
    "                sample = dataset[id_map[labelbox_id]]\n",
    "            elif download_dir:\n",
    "                # Download image and create new sample\n",
    "                # @todo optimize by downloading images in a background thread\n",
    "                # pool?\n",
    "                image_url = d[\"Labeled Data\"]\n",
    "                filepath = filename_maker.get_output_path(image_url)\n",
    "                etaw.download_file(image_url, path=filepath, quiet=True)\n",
    "                sample = fos.Sample(filepath=filepath)\n",
    "                dataset.add_sample(sample)\n",
    "            else:\n",
    "                logger.info(\n",
    "                    \"Skipping labels for unknown Labelbox ID '%s'; provide a \"\n",
    "                    \"`download_dir` if you wish to download media and create \"\n",
    "                    \"samples for new media\",\n",
    "                    labelbox_id,\n",
    "                )\n",
    "                continue\n",
    "\n",
    "            if sample.metadata is None:\n",
    "                if is_video:\n",
    "                    sample.metadata = fom.VideoMetadata.build_for(\n",
    "                        sample.filepath\n",
    "                    )\n",
    "                else:\n",
    "                    sample.metadata = fom.ImageMetadata.build_for(\n",
    "                        sample.filepath\n",
    "                    )\n",
    "\n",
    "            if is_video:\n",
    "                frame_size = (\n",
    "                    sample.metadata.frame_width,\n",
    "                    sample.metadata.frame_height,\n",
    "                )\n",
    "                frames = _parse_video_labels(d[\"Label\"], frame_size)\n",
    "                sample.frames.merge(\n",
    "                    {\n",
    "                        frame_number: {\n",
    "                            label_key(fname): flabel\n",
    "                            for fname, flabel in frame_dict.items()\n",
    "                        }\n",
    "                        for frame_number, frame_dict in frames.items()\n",
    "                    }\n",
    "                )\n",
    "            else:\n",
    "                frame_size = (sample.metadata.width, sample.metadata.height)\n",
    "                labels_dict = _parse_image_labels(d[\"Label\"], frame_size)\n",
    "                sample.update_fields(\n",
    "                    {label_key(k): v for k, v in labels_dict.items()}\n",
    "                )\n",
    "\n",
    "            sample.save()\n",
    "\n",
    "def _convert_labelbox_frames_export_to_import(inpath, outpath):\n",
    "    din_list = etas.read_ndjson(inpath)\n",
    "\n",
    "    dout_map = {}\n",
    "\n",
    "    for din in din_list:\n",
    "        frame_number = din.pop(\"frameNumber\")\n",
    "        din.pop(\"dataRow\")\n",
    "        din.pop(\"uuid\")\n",
    "\n",
    "        if frame_number not in dout_map:\n",
    "            dout_map[frame_number] = {\n",
    "                \"frameNumber\": frame_number,\n",
    "                \"objects\": [],\n",
    "                \"classifications\": [],\n",
    "            }\n",
    "\n",
    "        _ingest_label(din, dout_map[frame_number])\n",
    "\n",
    "    dout = [dout_map[fn] for fn in sorted(dout_map.keys())]\n",
    "    etas.write_ndjson(dout, outpath)\n",
    "\n",
    "\n",
    "def _ingest_label(din, d_label):\n",
    "    if any(k in din for k in (\"bbox\", \"polygon\", \"line\", \"point\", \"mask\")):\n",
    "        # Object\n",
    "        if \"mask\" in din:\n",
    "            din[\"instanceURI\"] = din.pop(\"mask\")[\"instanceURI\"]\n",
    "\n",
    "        d_label[\"objects\"].append(din)\n",
    "    else:\n",
    "        # Classification\n",
    "        d_label[\"classifications\"].append(din)\n",
    "\n",
    "\n",
    "def _get_labels(sample_or_frame, label_fields):\n",
    "    labels_dict = {}\n",
    "    for field, key in label_fields.items():\n",
    "        value = sample_or_frame[field]\n",
    "        if value is not None:\n",
    "            labels_dict[key] = value\n",
    "\n",
    "    return labels_dict\n",
    "\n",
    "\n",
    "def _get_frame_labels(sample, frame_label_fields):\n",
    "    frames = {}\n",
    "    for frame_number, frame in sample.frames.items():\n",
    "        frames[frame_number] = _get_labels(frame, frame_label_fields)\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "def _to_labelbox_image_labels(labels_dict, frame_size, data_row_id):\n",
    "    annotations = []\n",
    "    for name, label in labels_dict.items():\n",
    "        if isinstance(label, (fol.Classification, fol.Classifications)):\n",
    "            anno = _to_global_classification(name, label, data_row_id)\n",
    "            annotations.append(anno)\n",
    "        elif isinstance(label, (fol.Detection, fol.Detections)):\n",
    "            annos = _to_detections(label, frame_size, data_row_id)\n",
    "            annotations.extend(annos)\n",
    "        elif isinstance(label, (fol.Polyline, fol.Polylines)):\n",
    "            annos = _to_polylines(label, frame_size, data_row_id)\n",
    "            annotations.extend(annos)\n",
    "        elif isinstance(label, (fol.Keypoint, fol.Keypoints)):\n",
    "            annos = _to_points(label, frame_size, data_row_id)\n",
    "            annotations.extend(annos)\n",
    "        elif isinstance(label, fol.Segmentation):\n",
    "            annos = _to_mask(name, label, data_row_id)\n",
    "            annotations.extend(annos)\n",
    "        elif label is not None:\n",
    "            msg = \"Ignoring unsupported label type '%s'\" % label.__class__\n",
    "            warnings.warn(msg)\n",
    "\n",
    "    return annotations\n",
    "\n",
    "\n",
    "def _to_labelbox_video_labels(frames, frame_size, data_row_id):\n",
    "    annotations = []\n",
    "    for frame_number, labels_dict in frames.items():\n",
    "        frame_annos = _to_labelbox_image_labels(\n",
    "            labels_dict, frame_size, data_row_id\n",
    "        )\n",
    "        for anno in frame_annos:\n",
    "            anno[\"frameNumber\"] = frame_number\n",
    "            annotations.append(anno)\n",
    "\n",
    "    return annotations\n",
    "\n",
    "\n",
    "# https://labelbox.com/docs/exporting-data/export-format-detail#classification\n",
    "def _to_global_classification(name, label, data_row_id):\n",
    "    anno = _make_base_anno(name, data_row_id=data_row_id)\n",
    "    anno.update(_make_classification_answer(label))\n",
    "    return anno\n",
    "\n",
    "\n",
    "# https://labelbox.com/docs/exporting-data/export-format-detail#nested_classification\n",
    "def _to_nested_classifications(attributes):\n",
    "    classifications = []\n",
    "    for name, attr in attributes.items():\n",
    "        if not isinstance(attr, (fol.CategoricalAttribute, fol.ListAttribute)):\n",
    "            msg = \"Ignoring unsupported attribute type '%s'\" % attr.__class__\n",
    "            warnings.warn(msg)\n",
    "            continue\n",
    "\n",
    "        anno = _make_base_anno(name)\n",
    "        anno.update(_make_classification_answer(attr))\n",
    "        classifications.append(anno)\n",
    "\n",
    "    return classifications\n",
    "\n",
    "\n",
    "# https://labelbox.com/docs/automation/model-assisted-labeling#mask_annotations\n",
    "def _to_mask(name, label, data_row_id):\n",
    "    mask = np.asarray(label.mask)\n",
    "    if mask.ndim < 3 or mask.dtype != np.uint8:\n",
    "        raise ValueError(\n",
    "            \"Segmentation masks must be stored as RGB color uint8 images\"\n",
    "        )\n",
    "\n",
    "    try:\n",
    "        instance_uri = label.instance_uri\n",
    "    except:\n",
    "        raise ValueError(\n",
    "            \"You must populate the `instance_uri` field of segmentation masks\"\n",
    "        )\n",
    "\n",
    "    # Get unique colors\n",
    "    colors = np.unique(np.reshape(mask, (-1, 3)), axis=0).tolist()\n",
    "\n",
    "    annos = []\n",
    "    base_anno = _make_base_anno(name, data_row_id=data_row_id)\n",
    "    for color in colors:\n",
    "        anno = copy(base_anno)\n",
    "        anno[\"mask\"] = _make_mask(instance_uri, color)\n",
    "        annos.append(anno)\n",
    "\n",
    "    return annos\n",
    "\n",
    "\n",
    "# https://labelbox.com/docs/exporting-data/export-format-detail#bounding_boxes\n",
    "def _to_detections(label, frame_size, data_row_id):\n",
    "    if isinstance(label, fol.Detections):\n",
    "        detections = label.detections\n",
    "    else:\n",
    "        detections = [label]\n",
    "\n",
    "    annos = []\n",
    "    for detection in detections:\n",
    "        anno = _make_base_anno(detection.label, data_row_id=data_row_id)\n",
    "        anno[\"bbox\"] = _make_bbox(detection.bounding_box, frame_size)\n",
    "        if detection.attributes:\n",
    "            anno[\"classifications\"] = _to_nested_classifications(\n",
    "                detection.attributes\n",
    "            )\n",
    "\n",
    "        annos.append(anno)\n",
    "\n",
    "    return annos\n",
    "\n",
    "\n",
    "# https://labelbox.com/docs/exporting-data/export-format-detail#polygons\n",
    "# https://labelbox.com/docs/exporting-data/export-format-detail#polylines\n",
    "def _to_polylines(label, frame_size, data_row_id):\n",
    "    if isinstance(label, fol.Polylines):\n",
    "        polylines = label.polylines\n",
    "    else:\n",
    "        polylines = [label]\n",
    "\n",
    "    annos = []\n",
    "    for polyline in polylines:\n",
    "        field = \"polygon\" if polyline.filled else \"line\"\n",
    "        if polyline.attributes:\n",
    "            classifications = _to_nested_classifications(polyline.attributes)\n",
    "        else:\n",
    "            classifications = None\n",
    "\n",
    "        for points in polyline.points:\n",
    "            anno = _make_base_anno(polyline.label, data_row_id=data_row_id)\n",
    "            anno[field] = [_make_point(point, frame_size) for point in points]\n",
    "            if classifications is not None:\n",
    "                anno[\"classifications\"] = classifications\n",
    "\n",
    "            annos.append(anno)\n",
    "\n",
    "    return annos\n",
    "\n",
    "\n",
    "# https://labelbox.com/docs/exporting-data/export-format-detail#points\n",
    "def _to_points(label, frame_size, data_row_id):\n",
    "    if isinstance(label, fol.Keypoints):\n",
    "        keypoints = label.keypoints\n",
    "    else:\n",
    "        keypoints = [keypoints]\n",
    "\n",
    "    annos = []\n",
    "    for keypoint in keypoints:\n",
    "        if keypoint.attributes:\n",
    "            classifications = _to_nested_classifications(keypoint.attributes)\n",
    "        else:\n",
    "            classifications = None\n",
    "\n",
    "        for point in keypoint.points:\n",
    "            anno = _make_base_anno(keypoint.label, data_row_id=data_row_id)\n",
    "            anno[\"point\"] = _make_point(point, frame_size)\n",
    "            if classifications is not None:\n",
    "                anno[\"classifications\"] = classifications\n",
    "\n",
    "            annos.append(anno)\n",
    "\n",
    "    return annos\n",
    "\n",
    "\n",
    "def _make_base_anno(value, data_row_id=None):\n",
    "    anno = {\n",
    "        \"uuid\": str(uuid4()),\n",
    "        \"schemaId\": None,\n",
    "        \"title\": value,\n",
    "        \"value\": value,\n",
    "    }\n",
    "\n",
    "    if data_row_id:\n",
    "        anno[\"dataRow\"] = {\"id\": data_row_id}\n",
    "\n",
    "    return anno\n",
    "\n",
    "\n",
    "def _make_video_anno(labels_path, data_row_id=None):\n",
    "    anno = {\n",
    "        \"uuid\": str(uuid4()),\n",
    "        \"frames\": labels_path,\n",
    "    }\n",
    "\n",
    "    if data_row_id:\n",
    "        anno[\"dataRow\"] = {\"id\": data_row_id}\n",
    "\n",
    "    return anno\n",
    "\n",
    "\n",
    "def _make_classification_answer(label):\n",
    "    if isinstance(label, fol.Classification):\n",
    "        # Assume free text\n",
    "        return {\"answer\": label.label}\n",
    "\n",
    "    if isinstance(label, fol.Classifications):\n",
    "        # Assume checklist\n",
    "        answers = []\n",
    "        for classification in label.classifications:\n",
    "            answers.append({\"value\": classification.label})\n",
    "\n",
    "        return {\"answers\": answers}\n",
    "\n",
    "    if isinstance(label, fol.CategoricalAttribute):\n",
    "        # Assume free text\n",
    "        return {\"answer\": label.value}\n",
    "\n",
    "    if isinstance(label, fol.ListAttribute):\n",
    "        # Assume checklist\n",
    "        answers = []\n",
    "        for value in label.value:\n",
    "            answers.append({\"value\": value})\n",
    "\n",
    "        return {\"answers\": answers}\n",
    "\n",
    "    raise ValueError(\"Cannot convert %s to a classification\" % label.__class__)\n",
    "\n",
    "\n",
    "def _make_bbox(bounding_box, frame_size):\n",
    "    x, y, w, h = bounding_box\n",
    "    width, height = frame_size\n",
    "    return {\n",
    "        \"left\": round(x * width, 1),\n",
    "        \"top\": round(y * height, 1),\n",
    "        \"width\": round(w * width, 1),\n",
    "        \"height\": round(h * height, 1),\n",
    "    }\n",
    "\n",
    "\n",
    "def _make_point(point, frame_size):\n",
    "    x, y = point\n",
    "    width, height = frame_size\n",
    "    return {\"x\": round(x * width, 1), \"y\": round(y * height, 1)}\n",
    "\n",
    "\n",
    "def _make_mask(instance_uri, color):\n",
    "    return {\n",
    "        \"instanceURI\": instance_uri,\n",
    "        \"colorRGB\": list(color),\n",
    "    }\n",
    "\n",
    "\n",
    "# https://labelbox.com/docs/exporting-data/export-format-detail#video\n",
    "def _parse_video_labels(video_label_d, frame_size):\n",
    "    url_or_filepath = video_label_d[\"frames\"]\n",
    "    label_d_list = _download_or_load_ndjson(url_or_filepath)\n",
    "\n",
    "    frames = {}\n",
    "    for label_d in label_d_list:\n",
    "        frame_number = label_d[\"frameNumber\"]\n",
    "        frames[frame_number] = _parse_image_labels(label_d, frame_size)\n",
    "\n",
    "    return frames\n",
    "\n",
    "\n",
    "# https://labelbox.com/docs/exporting-data/export-format-detail#images\n",
    "def _parse_image_labels(label_d, frame_size):\n",
    "    labels = {}\n",
    "\n",
    "    # Parse classifications\n",
    "    cd_list = label_d.get(\"classifications\", [])\n",
    "    classifications = _parse_classifications(cd_list)\n",
    "    labels.update(classifications)\n",
    "\n",
    "    # Parse objects\n",
    "    # @todo what if `objects.keys()` conflicts with `classifications.keys()`?\n",
    "    od_list = label_d.get(\"objects\", [])\n",
    "    objects = _parse_objects(od_list, frame_size)\n",
    "    labels.update(objects)\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def _parse_classifications(cd_list):\n",
    "    labels = {}\n",
    "\n",
    "    for cd in cd_list:\n",
    "        name = cd[\"value\"]\n",
    "        if \"answer\" in cd:\n",
    "            answer = cd[\"answer\"]\n",
    "            if isinstance(answer, list):\n",
    "                # Dropdown\n",
    "                labels[name] = fol.Classifications(\n",
    "                    classifications=[\n",
    "                        fol.Classification(label=a[\"value\"]) for a in answer\n",
    "                    ]\n",
    "                )\n",
    "            elif isinstance(answer, dict):\n",
    "                # Radio question\n",
    "                labels[name] = fol.Classification(label=answer[\"value\"])\n",
    "            else:\n",
    "                # Free text\n",
    "                labels[name] = fol.Classification(label=answer)\n",
    "\n",
    "        if \"answers\" in cd:\n",
    "            # Checklist\n",
    "            answers = cd[\"answers\"]\n",
    "            labels[name] = fol.Classifications(\n",
    "                classifications=[\n",
    "                    fol.Classification(label=a[\"value\"]) for a in answers\n",
    "                ]\n",
    "            )\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def _parse_attributes(cd_list):\n",
    "    attributes = {}\n",
    "\n",
    "    for cd in cd_list:\n",
    "        name = cd[\"value\"]\n",
    "        if \"answer\" in cd:\n",
    "            answer = cd[\"answer\"]\n",
    "            if isinstance(answer, list):\n",
    "                # Dropdown\n",
    "                attributes[name] = fol.ListAttribute(\n",
    "                    value=[a[\"value\"] for a in answer]\n",
    "                )\n",
    "            elif isinstance(answer, dict):\n",
    "                # Radio question\n",
    "                attributes[name] = fol.CategoricalAttribute(\n",
    "                    value=answer[\"value\"]\n",
    "                )\n",
    "            else:\n",
    "                # Free text\n",
    "                attributes[name] = fol.CategoricalAttribute(value=answer)\n",
    "\n",
    "        if \"answers\" in cd:\n",
    "            # Checklist\n",
    "            answers = cd[\"answers\"]\n",
    "            attributes[name] = fol.ListAttribute(\n",
    "                value=[a[\"value\"] for a in answers]\n",
    "            )\n",
    "\n",
    "    return attributes\n",
    "\n",
    "\n",
    "def _parse_objects(od_list, frame_size):\n",
    "    detections = []\n",
    "    polylines = []\n",
    "    keypoints = []\n",
    "    mask = None\n",
    "    mask_instance_uri = None\n",
    "    for od in od_list:\n",
    "        label = od[\"value\"]\n",
    "        attributes = _parse_attributes(od.get(\"classifications\", []))\n",
    "\n",
    "        if \"bbox\" in od:\n",
    "            # Detection\n",
    "            bounding_box = _parse_bbox(od[\"bbox\"], frame_size)\n",
    "            detections.append(\n",
    "                fol.Detection(\n",
    "                    label=label,\n",
    "                    bounding_box=bounding_box,\n",
    "                    attributes=attributes,\n",
    "                )\n",
    "            )\n",
    "        elif \"polygon\" in od:\n",
    "            # Polyline\n",
    "            points = _parse_points(od[\"polygon\"], frame_size)\n",
    "            polylines.append(\n",
    "                fol.Polyline(\n",
    "                    label=label,\n",
    "                    points=[points],\n",
    "                    closed=True,\n",
    "                    filled=True,\n",
    "                    attributes=attributes,\n",
    "                )\n",
    "            )\n",
    "        elif \"line\" in od:\n",
    "            # Polyline\n",
    "            points = _parse_points(od[\"line\"], frame_size)\n",
    "            polylines.append(\n",
    "                fol.Polyline(\n",
    "                    label=label,\n",
    "                    points=[points],\n",
    "                    closed=True,\n",
    "                    filled=False,\n",
    "                    attributes=attributes,\n",
    "                )\n",
    "            )\n",
    "        elif \"point\" in od:\n",
    "            # Polyline\n",
    "            point = _parse_point(od[\"point\"], frame_size)\n",
    "            keypoints.append(\n",
    "                fol.Keypoint(\n",
    "                    label=label, points=[point], attributes=attributes,\n",
    "                )\n",
    "            )\n",
    "        elif \"instanceURI\" in od:\n",
    "            # Segmentation mask\n",
    "            if mask is None:\n",
    "                mask_instance_uri = od[\"instanceURI\"]\n",
    "                mask = _parse_mask(mask_instance_uri)\n",
    "            elif od[\"instanceURI\"] != mask_instance_uri:\n",
    "                msg = (\n",
    "                    \"Only one segmentation mask per image/frame is allowed; \"\n",
    "                    \"skipping additional mask(s)\"\n",
    "                )\n",
    "                warnings.warn(msg)\n",
    "        else:\n",
    "            msg = \"Ignoring unsupported label\"\n",
    "            warnings.warn(msg)\n",
    "\n",
    "    labels = {}\n",
    "\n",
    "    if detections:\n",
    "        labels[\"detections\"] = fol.Detections(detections=detections)\n",
    "\n",
    "    if polylines:\n",
    "        labels[\"polylines\"] = fol.Polylines(polylines=polylines)\n",
    "\n",
    "    if keypoints:\n",
    "        labels[\"keypoints\"] = fol.Keypoints(keypoints=keypoints)\n",
    "\n",
    "    if mask is not None:\n",
    "        labels[\"segmentation\"] = mask\n",
    "\n",
    "    return labels\n",
    "\n",
    "\n",
    "def _parse_bbox(bd, frame_size):\n",
    "    width, height = frame_size\n",
    "    x = bd[\"left\"] / width\n",
    "    y = bd[\"top\"] / height\n",
    "    w = bd[\"width\"] / width\n",
    "    h = bd[\"height\"] / height\n",
    "    return [x, y, w, h]\n",
    "\n",
    "\n",
    "def _parse_points(pd_list, frame_size):\n",
    "    return [_parse_point(pd, frame_size) for pd in pd_list]\n",
    "\n",
    "\n",
    "def _parse_point(pd, frame_size):\n",
    "    width, height = frame_size\n",
    "    return (pd[\"x\"] / width, pd[\"y\"] / height)\n",
    "\n",
    "\n",
    "def _parse_mask(instance_uri):\n",
    "    img_bytes = etaw.download_file(instance_uri, quiet=True)\n",
    "    return etai.decode(img_bytes)\n",
    "\n",
    "\n",
    "def _download_or_load_ndjson(url_or_filepath):\n",
    "    if url_or_filepath.startswith(\"http\"):\n",
    "        ndjson_bytes = etaw.download_file(url_or_filepath, quiet=True)\n",
    "        return etas.load_ndjson(ndjson_bytes)\n",
    "\n",
    "    return etas.read_ndjson(url_or_filepath)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Labelbox Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports and configuration \n",
    "import fiftyone as fo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['jsm-test-dataset', 'plane-dataset']\n"
     ]
    }
   ],
   "source": [
    "# function to help printing out dataset names\n",
    "#print(fo.list_datasets())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do the groundwork for importing, setup the dataset\n",
    "import fiftyone.utils.labelbox as foul\n",
    "from uuid import uuid4\n",
    "\n",
    "# expect an error here if the dataset already exists\n",
    "dataset = fo.load_dataset(DATASET_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name:        jsm-test-dataset\n",
      "Media type:  image\n",
      "Num samples: 5151\n",
      "Persistent:  True\n",
      "Tags:        []\n",
      "Sample fields:\n",
      "    filepath:     fiftyone.core.fields.StringField\n",
      "    tags:         fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
      "    external_id:  fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    bearing:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    elevation:    fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    distance:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    icao24:       fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    model:        fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    manufacturer: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    norm_model:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    labelbox_id:  fiftyone.core.fields.StringField\n"
     ]
    }
   ],
   "source": [
    "# TODO: Potentially delete\n",
    "# Adding a LABELBOX_ID_FIELD if it doesn't already exist\n",
    "#dataset.add_sample_field(LABELBOX_ID_FIELD, fo.StringField) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Skipping labels for unknown Labelbox ID 'ckou3botb2y0d0yw47ftmggdr'; provide a `download_dir` if you wish to download media and create samples for new media\n",
      " 100% |███████████████████| 56/56 [2.8s elapsed, 0s remaining, 19.7 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# Imports the data from Labelbox into a Voxel51 Dataset\n",
    "custom_import_from_labelbox(dataset,\n",
    "                          LABELBOX_EXPORT_JSON,\n",
    "                          labelbox_id_field=LABELBOX_ID_FIELD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examine the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = fo.launch_app(dataset, auto=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Post Processing\n",
    "You may want to do some additional data munging. I added a tag based on whether a plane was labeled or skipped in Labelbox."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a label & tag that captures if the image was skipped, indicating there was no plane, or accepted, indicating there was a plane\n",
    "from fiftyone import ViewField as F\n",
    "label_field = \"plane_ground_truth\" \n",
    "\n",
    "model_view = dataset.exists(\"model\")\n",
    "for sample in model_view:\n",
    "    sample[label_field] = fo.Classification(label=\"plane\")\n",
    "    sample.tags.append(\"plane\")\n",
    "    sample.save()\n",
    "\n",
    "\n",
    "skipped_view = dataset.match({\"model\": {\"$exists\": False, \"$eq\": None}})\n",
    "for sample in skipped_view:\n",
    "    #print(sample)\n",
    "    sample[label_field] = fo.Classification(label=\"noplane\")\n",
    "    sample.tags.append(\"noPlane\")\n",
    "    sample.save()    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
