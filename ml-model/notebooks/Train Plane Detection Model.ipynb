{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train a Plane Detection Model from Voxel51 Dataset\n",
    "This notebook trains a plane detection model using transfer learning. \n",
    "Depending on the label used, it can just detect a plane or it can try to detect the model of the plane.\n",
    "A pre-trained model is used as a starting point. This means that fewer example images are needed and the training process is faster.\n",
    "\n",
    "Images are exported from a Voxel51 Dataset into TensorFlow Records.The examples in the TFRecord are based on a selected Field from the Samples in the Voxel51 dataset. The V51 Sample field you choose should have 1 or more \"detections\", which are bounding boxes with a label.\n",
    "\n",
    "From: https://colab.research.google.com/drive/1sLqFKVV94wm-lglFq_0kGo2ciM0kecWD#scrollTo=wHfsJ5nWLWh9&uniqifier=1\n",
    "\n",
    "Good stuff here too: https://www.inovex.de/blog/deep-learning-mobile-tensorflow-lite/ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure the Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_name=\"881images-efficientdet-d0-model\" # The name for the model. All of the different directories will be based on this\n",
    "label_field = \"detections\"  # The field from the V51 Samples around which will be used for the Labels for training.\n",
    "dataset_name = \"jsm-test-dataset\" # The name of the V51 dataset that will be used\n",
    "\n",
    "\n",
    "# Available Model Configs (You can add more from the TF2 Model Zoo)\n",
    "MODELS_CONFIG = {\n",
    "    'ssd_mobilenet_v2': {\n",
    "        'model_name': 'ssd_mobilenet_v2_320x320_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_320x320_coco17_tpu-8.tar.gz',\n",
    "        'batch_size': 24\n",
    "    },\n",
    "    'ssd_mobilenet_v2_fpnlite': {\n",
    "        'model_name': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8',\n",
    "        'base_pipeline_file': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'ssd_mobilenet_v2_fpnlite_640x640_coco17_tpu-8.tar.gz',\n",
    "        'batch_size': 18\n",
    "    },\n",
    "    'efficientdet-d0': {\n",
    "        'model_name': 'efficientdet_d0_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d0_512x512_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d0_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 18\n",
    "    },\n",
    "    'efficientdet-d1': {\n",
    "        'model_name': 'efficientdet_d1_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d1_640x640_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d1_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 18\n",
    "    },\n",
    "    'efficientdet-d2': {\n",
    "        'model_name': 'efficientdet_d2_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d2_768x768_coco17_tpu-8.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d2_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 18\n",
    "    },\n",
    "        'efficientdet-d3': {\n",
    "        'model_name': 'efficientdet_d3_coco17_tpu-32',\n",
    "        'base_pipeline_file': 'ssd_efficientdet_d3_896x896_coco17_tpu-32.config',\n",
    "        'pretrained_checkpoint': 'efficientdet_d3_coco17_tpu-32.tar.gz',\n",
    "        'batch_size': 18\n",
    "    }\n",
    "}\n",
    "\n",
    "# change chosen model to deploy different models \n",
    "chosen_model = 'efficientdet-d0' #'ssd_mobilenet_v2'\n",
    "\n",
    "num_steps = 40000 # The more steps, the longer the training. Increase if your loss function is still decreasing and validation metrics are increasing. \n",
    "num_eval_steps = 500 # Perform evaluation after so many steps\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The different directories and filenames to use\n",
    "train_record_fname = \"/tf/dataset-export/\" + training_name + \"/train/tf.records\"\n",
    "val_record_fname = \"/tf/dataset-export/\" + training_name + \"/val/tf.records\"\n",
    "val_export_dir = \"/tf/dataset-export/\" + training_name + \"/val/\"\n",
    "train_export_dir = \"/tf/dataset-export/\" + training_name + \"/train/\"\n",
    "model_export_dir = \"/tf/model-export/\" + training_name +\"/\"\n",
    "\n",
    "label_map_file = \"/tf/dataset-export/\" + training_name + \"/label_map.pbtxt\"\n",
    "\n",
    "model_name = MODELS_CONFIG[chosen_model]['model_name']\n",
    "pretrained_checkpoint = MODELS_CONFIG[chosen_model]['pretrained_checkpoint']\n",
    "base_pipeline_file = MODELS_CONFIG[chosen_model]['base_pipeline_file']\n",
    "batch_size = MODELS_CONFIG[chosen_model]['batch_size'] #if you can fit a large batch in memory, it may speed up your training\n",
    "\n",
    "pipeline_fname = '/tf/models/research/deploy/' + base_pipeline_file\n",
    "fine_tune_checkpoint = '/tf/models/research/deploy/' + model_name + '/checkpoint/ckpt-0'\n",
    "pipeline_file = '/tf/models/research/deploy/pipeline_file.config'\n",
    "model_dir = '/tf/training/'+training_name+'/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "protobuf-compiler is already the newest version (3.0.0-9.1ubuntu1).\n",
      "libgl1-mesa-glx is already the newest version (20.0.8-0ubuntu1~18.04.1).\n",
      "wget is already the newest version (1.19.4-1ubuntu2.2).\n",
      "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\n"
     ]
    }
   ],
   "source": [
    "# Install the different packages needed\n",
    "#! apt install -y protobuf-compiler libgl1-mesa-glx wget"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download and Install TF Models\n",
    "The TF Object Detection API is available here: https://github.com/tensorflow/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path '/tf/models' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pathlib\n",
    "\n",
    "# Clone the tensorflow models repository if it doesn't already exist\n",
    "if \"models\" in pathlib.Path.cwd().parts:\n",
    "  while \"models\" in pathlib.Path.cwd().parts:\n",
    "    os.chdir('..')\n",
    "elif not pathlib.Path('models').exists():\n",
    "   # pull v2.5.0 of tensorflow models to make deterministic \n",
    "   !git clone --depth 1 https://github.com/tensorflow/models/tree/v2.5.0 /tf/models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "README.md\n",
      "adversarial_text\n",
      "attention_ocr\n",
      "audioset\n",
      "autoaugment\n",
      "cognitive_planning\n",
      "cvt_text\n",
      "deep_speech\n",
      "deeplab\n",
      "delf\n",
      "deploy\n",
      "efficient-hrl\n",
      "lfads\n",
      "lstm_object_detection\n",
      "marco\n",
      "nst_blogpost\n",
      "object_detection\n",
      "pcl_rl\n",
      "rebar\n",
      "seq_flow_lite\n",
      "setup.py\n",
      "slim\n",
      "vid2depth\n",
      "Processing /tf/models/research\n",
      "Requirement already satisfied: avro-python3 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.10.2)\n",
      "Requirement already satisfied: apache-beam in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.30.0)\n",
      "Requirement already satisfied: pillow in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (8.2.0)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (4.6.3)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: Cython in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.29.23)\n",
      "Requirement already satisfied: contextlib2 in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.6.0.post1)\n",
      "Requirement already satisfied: tf-slim in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.15.0)\n",
      "Requirement already satisfied: pycocotools in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.0.2)\n",
      "Requirement already satisfied: lvis in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (0.5.3)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.5.4)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (1.1.5)\n",
      "Requirement already satisfied: tf-models-official in /usr/local/lib/python3.6/dist-packages (from object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: fastavro<2,>=0.21.4 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.4.1)\n",
      "Requirement already satisfied: dill<0.3.2,>=0.3.1.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.3.1.1)\n",
      "Requirement already satisfied: pymongo<4.0.0,>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.11.4)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.24.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.25.1)\n",
      "Requirement already satisfied: typing-extensions<3.8.0,>=3.7.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.7.4.3)\n",
      "Requirement already satisfied: numpy<1.21.0,>=1.14.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.19.5)\n",
      "Requirement already satisfied: protobuf<4,>=3.12.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.17.0)\n",
      "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.8)\n",
      "Requirement already satisfied: crcmod<2.0,>=1.7 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.7)\n",
      "Requirement already satisfied: pytz>=2018.3 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2021.1)\n",
      "Requirement already satisfied: grpcio<2,>=1.29.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.34.1)\n",
      "Requirement already satisfied: hdfs<3.0.0,>=2.1.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.6.0)\n",
      "Requirement already satisfied: oauth2client<5,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (4.1.3)\n",
      "Requirement already satisfied: pydot<2,>=1.2.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (1.4.2)\n",
      "Requirement already satisfied: pyarrow<4.0.0,>=0.15.1 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (3.0.0)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (2.8.1)\n",
      "Requirement already satisfied: httplib2<0.20.0,>=0.8 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.19.1)\n",
      "Requirement already satisfied: future<1.0.0,>=0.18.2 in /usr/local/lib/python3.6/dist-packages (from apache-beam->object-detection==0.1) (0.18.2)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (0.10.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: absl-py>=0.2.2 in /usr/local/lib/python3.6/dist-packages (from tf-slim->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: setuptools>=18.0 in /usr/local/lib/python3.6/dist-packages (from pycocotools->object-detection==0.1) (56.2.0)\n",
      "Requirement already satisfied: opencv-python>=4.1.0.25 in /usr/local/lib/python3.6/dist-packages (from lvis->object-detection==0.1) (4.5.2.54)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.1)\n",
      "Requirement already satisfied: google-api-python-client>=1.6.7 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.10.0)\n",
      "Requirement already satisfied: kaggle>=1.3.9 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.5.12)\n",
      "Requirement already satisfied: py-cpuinfo>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (8.0.0)\n",
      "Requirement already satisfied: gin-config in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: tensorflow-datasets in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.3.0)\n",
      "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.1.96)\n",
      "Requirement already satisfied: psutil>=5.4.3 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.8.0)\n",
      "Requirement already satisfied: tensorflow>=2.5.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: opencv-python-headless in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (4.4.0.46)\n",
      "Requirement already satisfied: tensorflow-hub>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.12.0)\n",
      "Requirement already satisfied: google-cloud-bigquery>=0.31.0 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (2.20.0)\n",
      "Requirement already satisfied: seqeval in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (1.2.2)\n",
      "Requirement already satisfied: tensorflow-model-optimization>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.6.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (5.4.1)\n",
      "Requirement already satisfied: tensorflow-addons in /usr/local/lib/python3.6/dist-packages (from tf-models-official->object-detection==0.1) (0.13.0)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (1.26.4)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests<3.0.0,>=2.24.0->apache-beam->object-detection==0.1) (2.6)\n",
      "Requirement already satisfied: docopt in /usr/local/lib/python3.6/dist-packages (from hdfs<3.0.0,>=2.1.0->apache-beam->object-detection==0.1) (0.6.2)\n",
      "Requirement already satisfied: rsa>=3.1.4 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (4.7.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.7 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.4.8)\n",
      "Requirement already satisfied: pyasn1-modules>=0.0.5 in /usr/local/lib/python3.6/dist-packages (from oauth2client<5,>=2.0.1->apache-beam->object-detection==0.1) (0.2.8)\n",
      "Requirement already satisfied: portalocker==2.0.0 in /usr/local/lib/python3.6/dist-packages (from sacrebleu->tf-models-official->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: google-api-core<2dev,>=1.21.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.30.0)\n",
      "Requirement already satisfied: uritemplate<4dev,>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (3.0.1)\n",
      "Requirement already satisfied: google-auth-httplib2>=0.1.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (0.1.0)\n",
      "Requirement already satisfied: google-auth<2dev,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.30.0)\n",
      "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (4.61.1)\n",
      "Requirement already satisfied: python-slugify in /usr/local/lib/python3.6/dist-packages (from kaggle>=1.3.9->tf-models-official->object-detection==0.1) (5.0.2)\n",
      "Requirement already satisfied: termcolor in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: tensorflow-metadata in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (1.1.0)\n",
      "Requirement already satisfied: attrs>=18.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (21.2.0)\n",
      "Requirement already satisfied: importlib-resources; python_version < \"3.9\" in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (5.1.4)\n",
      "Requirement already satisfied: promise in /usr/local/lib/python3.6/dist-packages (from tensorflow-datasets->tf-models-official->object-detection==0.1) (2.3)\n",
      "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0)\n",
      "Requirement already satisfied: tensorflow-estimator<2.6.0,>=2.5.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0rc0)\n",
      "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.2.0)\n",
      "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12)\n",
      "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.36.2)\n",
      "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.0)\n",
      "Requirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.12.1)\n",
      "Requirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.0)\n",
      "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.6.3)\n",
      "Requirement already satisfied: keras-nightly~=2.5.0.dev in /usr/local/lib/python3.6/dist-packages (from tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.5.0.dev2021032900)\n",
      "Requirement already satisfied: google-resumable-media<2.0dev,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.3.1)\n",
      "Requirement already satisfied: proto-plus>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.18.1)\n",
      "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (20.9)\n",
      "Requirement already satisfied: google-cloud-core<2.0dev,>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.7.1)\n",
      "Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.6/dist-packages (from seqeval->tf-models-official->object-detection==0.1) (0.24.2)\n",
      "Requirement already satisfied: dm-tree~=0.1.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-model-optimization>=0.4.1->tf-models-official->object-detection==0.1) (0.1.6)\n",
      "Requirement already satisfied: typeguard>=2.7 in /usr/local/lib/python3.6/dist-packages (from tensorflow-addons->tf-models-official->object-detection==0.1) (2.12.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2dev,>=1.21.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (1.53.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2dev,>=1.16.0->google-api-python-client>=1.6.7->tf-models-official->object-detection==0.1) (4.2.2)\n",
      "Requirement already satisfied: text-unidecode>=1.3 in /usr/local/lib/python3.6/dist-packages (from python-slugify->kaggle>=1.3.9->tf-models-official->object-detection==0.1) (1.3)\n",
      "Requirement already satisfied: zipp>=3.1.0; python_version < \"3.10\" in /usr/local/lib/python3.6/dist-packages (from importlib-resources; python_version < \"3.9\"->tensorflow-datasets->tf-models-official->object-detection==0.1) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.8.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.6.1)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (2.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.3.4)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (0.4.4)\n",
      "Requirement already satisfied: cached-property; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from h5py~=3.1.0->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.5.2)\n",
      "Requirement already satisfied: google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\" in /usr/local/lib/python3.6/dist-packages (from google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.1.2)\n",
      "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (1.0.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn>=0.21.3->seqeval->tf-models-official->object-detection==0.1) (2.1.0)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (4.0.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (1.3.0)\n",
      "Requirement already satisfied: cffi>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (1.14.5)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.6/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow>=2.5.0->tf-models-official->object-detection==0.1) (3.1.0)\n",
      "Requirement already satisfied: pycparser in /usr/local/lib/python3.6/dist-packages (from cffi>=1.0.0->google-crc32c<2.0dev,>=1.0; python_version >= \"3.5\"->google-resumable-media<2.0dev,>=0.6.0->google-cloud-bigquery>=0.31.0->tf-models-official->object-detection==0.1) (2.20)\n",
      "Building wheels for collected packages: object-detection\n",
      "  Building wheel for object-detection (setup.py): started\n",
      "  Building wheel for object-detection (setup.py): finished with status 'done'\n",
      "  Created wheel for object-detection: filename=object_detection-0.1-py3-none-any.whl size=1650080 sha256=dcfc104b19e566c43faabaae7862c4923479cfe3849ae11e9717fb1fb9aabeee\n",
      "  Stored in directory: /tmp/pip-ephem-wheel-cache-qv3hkweu/wheels/1b/00/50/d3675d90b11a88efdd99ed80b60a2b19e5769a0bb333440375\n",
      "Successfully built object-detection\n",
      "Installing collected packages: object-detection\n",
      "  Attempting uninstall: object-detection\n",
      "    Found existing installation: object-detection 0.1\n",
      "    Uninstalling object-detection-0.1:\n",
      "      Successfully uninstalled object-detection-0.1\n",
      "Successfully installed object-detection-0.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are using pip version 20.2.4; however, version 21.1.2 is available.\n",
      "You should consider upgrading via the '/usr/local/bin/python -m pip install --upgrade pip' command.\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "cd /tf/models/research\n",
    "ls\n",
    "protoc object_detection/protos/*.proto --python_out=.\n",
    "cp object_detection/packages/tf2/setup.py .\n",
    "python -m pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap, StringIntLabelMapItem\n",
    "from google.protobuf import text_format\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export the Training and Val Dataset from Voxel 51"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import fiftyone as fo\n",
    "import math\n",
    "dataset = fo.load_dataset(dataset_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the dataset content\n",
    "Here are some basic stats on the Voxel51 dataset you are going to build training the model on. \n",
    "An example of the samples is also printed out. In the Sample, make sure the *label_field* you selected has some detections in it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t\tDataset\n",
      "-----------------------------------\n",
      "Dataset:     jsm-test-dataset\n",
      "Media type:  image\n",
      "Num samples: 881\n",
      "Tags:        ['capture-3-29', 'capture-3-30', 'capture-5-13', 'training']\n",
      "Sample fields:\n",
      "    id:                   fiftyone.core.fields.ObjectIdField\n",
      "    filepath:             fiftyone.core.fields.StringField\n",
      "    tags:                 fiftyone.core.fields.ListField(fiftyone.core.fields.StringField)\n",
      "    metadata:             fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.metadata.Metadata)\n",
      "    external_id:          fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    bearing:              fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    elevation:            fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    distance:             fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    icao24:               fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    model:                fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    manufacturer:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    norm_model:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    labelbox_id:          fiftyone.core.fields.StringField\n",
      "    detections:           fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    operatorcallsign:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Classification)\n",
      "    predict_model:        fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    dolt_predict:         fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    dolt_40k_predict:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    dolt_bg_predict:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    dolt_400_predict:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    400_predict:          fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    400_aug_5k_predict:   fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    914_mega_predict:     fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    914_40k_predict:      fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    914_40k_predict_full: fiftyone.core.fields.EmbeddedDocumentField(fiftyone.core.labels.Detections)\n",
      "    eval_tp:              fiftyone.core.fields.IntField\n",
      "    eval_fp:              fiftyone.core.fields.IntField\n",
      "    eval_fn:              fiftyone.core.fields.IntField\n",
      "View stages:\n",
      "    1. MatchTags(tags=['training'], bool=True)\n",
      "    2. Shuffle(seed=51)\n",
      "\n",
      "\n",
      "\tExample Sample\n",
      "-----------------------------------\n",
      "<SampleView: {\n",
      "    'id': '60a3bf2ef3610f2b7a828f88',\n",
      "    'media_type': 'image',\n",
      "    'filepath': '/tf/media/capture-5-13/Airbus Industrie A321-211/a11eb7_275_77_9303_2021-05-13-11-17-33.jpg',\n",
      "    'tags': BaseList(['training', 'capture-5-13']),\n",
      "    'metadata': <ImageMetadata: {\n",
      "        'size_bytes': 489161,\n",
      "        'mime_type': 'image/jpeg',\n",
      "        'width': 1920,\n",
      "        'height': 1080,\n",
      "        'num_channels': 3,\n",
      "    }>,\n",
      "    'external_id': <Classification: {\n",
      "        'id': '60a3bf2ef3610f2b7a828f83',\n",
      "        'tags': BaseList([]),\n",
      "        'label': 'a11eb7_275_77_9303_2021-05-13-11-17-33',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'bearing': <Classification: {\n",
      "        'id': '60a3bf2ef3610f2b7a828f84',\n",
      "        'tags': BaseList([]),\n",
      "        'label': '275',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'elevation': <Classification: {\n",
      "        'id': '60a3bf2ef3610f2b7a828f85',\n",
      "        'tags': BaseList([]),\n",
      "        'label': '77',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'distance': <Classification: {\n",
      "        'id': '60a3bf2ef3610f2b7a828f86',\n",
      "        'tags': BaseList([]),\n",
      "        'label': '9303',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'icao24': <Classification: {\n",
      "        'id': '60a3bf2ef3610f2b7a828f87',\n",
      "        'tags': BaseList([]),\n",
      "        'label': 'a11eb7',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'model': <Classification: {\n",
      "        'id': '60d5e7045e08d80243cba70b',\n",
      "        'tags': BaseList([]),\n",
      "        'label': 'A321-211',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'manufacturer': <Classification: {\n",
      "        'id': '60d5e7045e08d80243cba70c',\n",
      "        'tags': BaseList([]),\n",
      "        'label': 'Airbus Industrie',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'norm_model': <Classification: {\n",
      "        'id': '60d5e7ba5e08d80243ce5c32',\n",
      "        'tags': BaseList([]),\n",
      "        'label': 'A321',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'labelbox_id': 'ckou3l1fk9ns80y99bzz3fusq',\n",
      "    'detections': <Detections: {\n",
      "        'detections': BaseList([\n",
      "            <Detection: {\n",
      "                'id': '60e702f215f87e1a607696c7',\n",
      "                'attributes': BaseDict({}),\n",
      "                'tags': BaseList([]),\n",
      "                'label': 'plane',\n",
      "                'bounding_box': BaseList([\n",
      "                    0.5755208333333334,\n",
      "                    0.40185185185185185,\n",
      "                    0.121875,\n",
      "                    0.16296296296296298,\n",
      "                ]),\n",
      "                'mask': None,\n",
      "                'confidence': None,\n",
      "                'index': None,\n",
      "            }>,\n",
      "        ]),\n",
      "    }>,\n",
      "    'operatorcallsign': <Classification: {\n",
      "        'id': '60d5e7045e08d80243cba70d',\n",
      "        'tags': BaseList([]),\n",
      "        'label': 'AMERICAN',\n",
      "        'confidence': None,\n",
      "        'logits': None,\n",
      "    }>,\n",
      "    'predict_model': <Detections: {\n",
      "        'detections': BaseList([\n",
      "            <Detection: {\n",
      "                'id': '60d0ccaf218c23e19b1f9e85',\n",
      "                'attributes': BaseDict({}),\n",
      "                'tags': BaseList([]),\n",
      "                'label': 'plane',\n",
      "                'bounding_box': BaseList([\n",
      "                    0.5768705606460571,\n",
      "                    0.4023531973361969,\n",
      "                    0.12218141555786133,\n",
      "                    0.16684052348136902,\n",
      "                ]),\n",
      "                'mask': None,\n",
      "                'confidence': 0.9999737739562988,\n",
      "                'index': None,\n",
      "            }>,\n",
      "        ]),\n",
      "    }>,\n",
      "    'dolt_predict': <Detections: {\n",
      "        'detections': BaseList([\n",
      "            <Detection: {\n",
      "                'id': '60d35f37218c23e19b1fb5d0',\n",
      "                'attributes': BaseDict({}),\n",
      "                'tags': BaseList([]),\n",
      "                'label': 'plane',\n",
      "                'bounding_box': BaseList([\n",
      "                    0.5762593746185303,\n",
      "                    0.40124379263983834,\n",
      "                    0.12189579010009766,\n",
      "                    0.16604603661431205,\n",
      "                ]),\n",
      "                'mask': None,\n",
      "                'confidence': 0.9999697208404541,\n",
      "                'index': None,\n",
      "            }>,\n",
      "        ]),\n",
      "    }>,\n",
      "    'dolt_40k_predict': <Detections: {\n",
      "        'detections': BaseList([\n",
      "            <Detection: {\n",
      "                'id': '60d543ac20cf8e383b417810',\n",
      "                'attributes': BaseDict({}),\n",
      "                'tags': BaseList([]),\n",
      "                'label': 'plane',\n",
      "                'bounding_box': BaseList([\n",
      "                    0.5774428248405457,\n",
      "                    0.3997461001078288,\n",
      "                    0.11862397193908691,\n",
      "                    0.1671259138319227,\n",
      "                ]),\n",
      "                'mask': None,\n",
      "                'confidence': 1.0,\n",
      "                'index': None,\n",
      "            }>,\n",
      "        ]),\n",
      "    }>,\n",
      "    'dolt_bg_predict': None,\n",
      "    'dolt_400_predict': None,\n",
      "    '400_predict': <Detections: {\n",
      "        'detections': BaseList([\n",
      "            <Detection: {\n",
      "                'id': '60d7ee853f3353cca1d7c600',\n",
      "                'attributes': BaseDict({}),\n",
      "                'tags': BaseList([]),\n",
      "                'label': 'plane',\n",
      "                'bounding_box': BaseList([\n",
      "                    0.5755680799484253,\n",
      "                    0.4013982084062364,\n",
      "                    0.12205994129180908,\n",
      "                    0.16460511419508195,\n",
      "                ]),\n",
      "                'mask': None,\n",
      "                'confidence': 1.0,\n",
      "                'index': None,\n",
      "            }>,\n",
      "        ]),\n",
      "    }>,\n",
      "    '400_aug_5k_predict': None,\n",
      "    '914_mega_predict': None,\n",
      "    '914_40k_predict': <Detections: {\n",
      "        'detections': BaseList([\n",
      "            <Detection: {\n",
      "                'id': '60e4805010424668fddefc67',\n",
      "                'attributes': BaseDict({}),\n",
      "                'tags': BaseList([]),\n",
      "                'label': 'plane',\n",
      "                'bounding_box': BaseList([\n",
      "                    0.5735075355817875,\n",
      "                    0.40489327907562256,\n",
      "                    0.12403148040175438,\n",
      "                    0.1557837724685669,\n",
      "                ]),\n",
      "                'mask': None,\n",
      "                'confidence': 0.9985151886940002,\n",
      "                'index': None,\n",
      "            }>,\n",
      "        ]),\n",
      "    }>,\n",
      "    '914_40k_predict_full': None,\n",
      "    'eval_tp': None,\n",
      "    'eval_fp': None,\n",
      "    'eval_fn': None,\n",
      "}>\n"
     ]
    }
   ],
   "source": [
    "print(\"\\t\\tDataset\\n-----------------------------------\")\n",
    "view = dataset.match_tags(\"training\").shuffle(seed=51) # You can add additional things to the query to further refine it. eg .match_tags(\"good_box\")\n",
    "print(view)\n",
    "print(\"\\n\\n\\tExample Sample\\n-----------------------------------\")\n",
    "print(view.first())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export the dataset into TFRecords\n",
    "The selected dataset samples will be exported to TensorFlow Records (TFRecords). They will be split between Training and Validation. The ratio can be adjusted below. You only need to do this once to build the dataset. If you run this a second time with the same **model_name** additional samples will be appended to the end."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total: 881 Val: 176 Train: 704\n",
      " 100% |█████████████████| 176/176 [4.1s elapsed, 0s remaining, 52.9 samples/s]       \n",
      " 100% |█████████████████| 704/704 [13.2s elapsed, 0s remaining, 54.4 samples/s]      \n"
     ]
    }
   ],
   "source": [
    "# The Dataset or DatasetView to export\n",
    "sample_len = len(view)\n",
    "val_len = math.floor(sample_len * 0.2)\n",
    "train_len = math.floor(sample_len * 0.8)\n",
    "print(\"Total: {} Val: {} Train: {}\".format(sample_len,val_len,train_len))\n",
    "val_view = view.take(val_len)\n",
    "train_view = view.skip(val_len).take(train_len)\n",
    "# Export the dataset\n",
    "val_view.export(\n",
    "    export_dir=val_export_dir,\n",
    "    dataset_type=fo.types.TFObjectDetectionDataset,#fo.types.COCODetectionDataset,#fo.types.TFObjectDetectionDataset,\n",
    "    label_field=label_field,\n",
    ")\n",
    "\n",
    "train_view.export(\n",
    "    export_dir=train_export_dir,\n",
    "    dataset_type=fo.types.TFObjectDetectionDataset,#fo.types.COCODetectionDataset,#fo.types.TFObjectDetectionDataset,\n",
    "    label_field=label_field,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a file with the Labels for the objects\n",
    "The TF2 Object Detection API looks for a map of the labels used and a corresponding Id. You can build a list of the unique classnames by itterating the dataset. You can also just hardcode it if there only a few."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_classes(classes, start=1):\n",
    "    msg = StringIntLabelMap()\n",
    "    for id, name in enumerate(classes, start=start):\n",
    "        msg.item.append(StringIntLabelMapItem(id=id, name=name))\n",
    "\n",
    "    text = str(text_format.MessageToBytes(msg, as_utf8=True), 'utf-8')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If labelfield is a classification\n",
    "class_names=[]\n",
    "for sample in view.select_fields(label_field):\n",
    "    if sample[label_field].label not in class_names:\n",
    "        class_names.append(sample[label_field].label)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['plane']\n"
     ]
    }
   ],
   "source": [
    "# If labelfield is detections\n",
    "class_names=[]\n",
    "for sample in view.select_fields(label_field):\n",
    "    if sample[label_field] is not None:\n",
    "        for detection in sample[label_field].detections:     \n",
    "            label = detection[\"label\"]\n",
    "            if label not in class_names:\n",
    "                class_names.append(label)\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can hard wire it too\n",
    "class_names=[\"plane\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "item {\n",
      "  name: \"plane\"\n",
      "  id: 1\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "txt = convert_classes(class_names)\n",
    "print(txt)\n",
    "with open(label_map_file, 'w') as f:\n",
    "        f.write(txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download a pretrained Model & default Config\n",
    "A list of the models can be found here: https://github.com/tensorflow/models/blob/master/research/object_detection/g3doc/tf2_detection_zoo.md\n",
    "\n",
    "The configs are here: https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#download pretrained weights\n",
    "%mkdir /tf/models/research/deploy/\n",
    "%cd /tf/models/research/deploy/\n",
    "import tarfile\n",
    "download_tar = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/' + pretrained_checkpoint\n",
    "\n",
    "!wget {download_tar}\n",
    "tar = tarfile.open(pretrained_checkpoint)\n",
    "tar.extractall()\n",
    "tar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/models/research/deploy\n",
      "--2021-07-08 20:52:50--  https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/ssd_efficientdet_d0_512x512_coco17_tpu-8.config\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.111.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 4630 (4.5K) [text/plain]\n",
      "Saving to: ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.8’\n",
      "\n",
      "ssd_efficientdet_d0 100%[===================>]   4.52K  --.-KB/s    in 0s      \n",
      "\n",
      "2021-07-08 20:52:50 (43.3 MB/s) - ‘ssd_efficientdet_d0_512x512_coco17_tpu-8.config.8’ saved [4630/4630]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#download base training configuration file\n",
    "%cd /tf/models/research/deploy\n",
    "download_config = 'https://raw.githubusercontent.com/tensorflow/models/master/research/object_detection/configs/tf2/' + base_pipeline_file\n",
    "!wget {download_config}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the Config for training\n",
    "The default config for the model being trained needs to be updated with the correct parameters and paths to the data. This just adds some standard settings, you may need to do some additional tuning if the training is not working well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with 1 classes\n"
     ]
    }
   ],
   "source": [
    "# Gets the total number of classes from the Label Map\n",
    "\n",
    "def get_num_classes(pbtxt_fname):\n",
    "    from object_detection.utils import label_map_util\n",
    "    label_map = label_map_util.load_labelmap(pbtxt_fname)\n",
    "    categories = label_map_util.convert_label_map_to_categories(\n",
    "        label_map, max_num_classes=90, use_display_name=True)\n",
    "    category_index = label_map_util.create_category_index(categories)\n",
    "    return len(category_index.keys())\n",
    "num_classes = get_num_classes(label_map_file)\n",
    "print(\"working with {} classes\".format(num_classes))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You may need to adjust the learning rate section below. The number used here are from the EfficentDet config. I noticed that this learning rate worked well for the small bounding boxes I was using when planes were at a high altitude. You can try increasing it if the planes take up more of the image. If the initial loss rates are high (>0) that is a probably a sign that you should adjust the Learning Rate.\n",
    "\n",
    "You may also want to look at other aspects of the config file. They set the parameters for the model training and may need to be adjusted based on the Model Architecture you are using and the images you are training on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/models/research/deploy\n",
      "writing custom configuration file\n"
     ]
    }
   ],
   "source": [
    "# write custom configuration file by slotting our dataset, model checkpoint, and training parameters into the base pipeline file\n",
    "\n",
    "import re\n",
    "\n",
    "%cd /tf/models/research/deploy\n",
    "print('writing custom configuration file')\n",
    "\n",
    "with open(pipeline_fname) as f:\n",
    "    s = f.read()\n",
    "with open('pipeline_file.config', 'w') as f:\n",
    "    \n",
    "    # fine_tune_checkpoint\n",
    "    s = re.sub('fine_tune_checkpoint: \".*?\"',\n",
    "               'fine_tune_checkpoint: \"{}\"'.format(fine_tune_checkpoint), s)\n",
    "    \n",
    "    # tfrecord files train and test.\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/train)(.*?\")', 'input_path: \"{}\"'.format(train_record_fname), s)\n",
    "    s = re.sub(\n",
    "        '(input_path: \".*?)(PATH_TO_BE_CONFIGURED/val)(.*?\")', 'input_path: \"{}\"'.format(val_record_fname), s)\n",
    "\n",
    "    # label_map_path\n",
    "    s = re.sub(\n",
    "        'label_map_path: \".*?\"', 'label_map_path: \"{}\"'.format(label_map_file), s)\n",
    "\n",
    "    # Set training batch_size.\n",
    "    s = re.sub('batch_size: [0-9]+',\n",
    "               'batch_size: {}'.format(batch_size), s)\n",
    "\n",
    "    # Set training steps, num_steps\n",
    "    s = re.sub('num_steps: [0-9]+',\n",
    "               'num_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set learning_rate_base in learning_rate, sane default\n",
    "#     s = re.sub('learning_rate_base: [.0-9]+',\n",
    "#                'learning_rate_base: {}'.format(\"8e-2\"), s)\n",
    "    \n",
    "    # Set warmup_learning_rate in learning_rate, sane default\n",
    "    s = re.sub('warmup_learning_rate: [.0-9]+',\n",
    "               'warmup_learning_rate: {}'.format(.001), s)\n",
    "    \n",
    "    # Set warmup_steps in learning_rate, sane default\n",
    "    s = re.sub('warmup_steps: [.0-9]+',\n",
    "               'warmup_steps: {}'.format(2500), s)\n",
    "    \n",
    "    # Set total_steps in learning_rate, num_steps\n",
    "    s = re.sub('total_steps: [0-9]+',\n",
    "               'total_steps: {}'.format(num_steps), s)\n",
    "    \n",
    "    # Set number of classes num_classes.\n",
    "    s = re.sub('num_classes: [0-9]+',\n",
    "               'num_classes: {}'.format(num_classes), s)\n",
    "    \n",
    "    # Setup the data augmentation preprocessor - not sure if this is a good one to use, commenting out for now and going with defaults.\n",
    "    #s = re.sub('random_scale_crop_and_pad_to_square {\\s+output_size: 896\\s+scale_min: 0.1\\s+scale_max: 2.0\\s+}',\n",
    "    #           'random_crop_image {\\n\\tmin_object_covered: 1.0\\n\\tmin_aspect_ratio: 0.75\\n\\tmax_aspect_ratio: 1.5\\n\\tmin_area: 0.25\\n\\tmax_area: 0.875\\n\\toverlap_thresh: 0.5\\n\\trandom_coef: 0.125\\n}',s, flags=re.MULTILINE)\n",
    "    \n",
    "    #s = re.sub('ssd_random_crop {\\s+}',\n",
    "    #           'random_crop_image {\\n\\tmin_object_covered: 1.0\\n\\tmin_aspect_ratio: 0.75\\n\\tmax_aspect_ratio: 1.5\\n\\tmin_area: 0.10\\n\\tmax_area: 0.75\\n\\toverlap_thresh: 0.5\\n\\trandom_coef: 0.125\\n}',s, flags=re.MULTILINE)\n",
    "    \n",
    "    # replacing the default data augmentation with something more comprehensive\n",
    "    # the available options are listed here: https://github.com/tensorflow/models/blob/master/research/object_detection/protos/preprocessor.proto\n",
    "    \n",
    "    data_augmentation = (\"data_augmentation_options {\\n random_distort_color: { \\n } \\n}\\n\\n\"\n",
    "        \"data_augmentation_options {\\n random_horizontal_flip: { \\n } \\n}\\n\\n\"\n",
    "        \"data_augmentation_options {\\n random_vertical_flip: { \\n } \\n}\\n\\n\"\n",
    "        \"data_augmentation_options {\\n random_rotation90: { \\n } \\n}\\n\\n\"\n",
    "        \"data_augmentation_options {\\n random_jitter_boxes: { \\n } \\n}\\n\\n\"\n",
    "        \"data_augmentation_options {\\n random_crop_image {\\n\\tmin_object_covered: 1.0\\n\\tmin_aspect_ratio: 0.95\\n\\tmax_aspect_ratio: 1.05\\n\\tmin_area: 0.25\\n\\tmax_area: 0.875\\n\\toverlap_thresh: 0.9\\n\\trandom_coef: 0.5\\n}\\n}\\n\\n\"\n",
    "        \"data_augmentation_options {\\n random_jpeg_quality: {\\n\\trandom_coef: 0.5\\n\\tmin_jpeg_quality: 40\\n\\tmax_jpeg_quality: 90\\n } \\n}\\n\\n\"\n",
    "    )\n",
    "    \n",
    "    s = re.sub('data_augmentation_options {[\\s\\w]*{[\\s\\w\\:\\.]*}\\s*}\\s* data_augmentation_options {[\\s\\w]*{[\\s\\w\\:\\.]*}\\s*}',\n",
    "               data_augmentation,s, flags=re.MULTILINE)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #fine-tune checkpoint type\n",
    "    s = re.sub(\n",
    "        'fine_tune_checkpoint_type: \"classification\"', 'fine_tune_checkpoint_type: \"{}\"'.format('detection'), s)\n",
    "        \n",
    "    f.write(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " # SSD with EfficientNet-b0 + BiFPN feature extractor,\r\n",
      "# shared box predictor and focal loss (a.k.a EfficientDet-d0).\r\n",
      "# See EfficientDet, Tan et al, https://arxiv.org/abs/1911.09070\r\n",
      "# See Lin et al, https://arxiv.org/abs/1708.02002\r\n",
      "# Trained on COCO, initialized from an EfficientNet-b0 checkpoint.\r\n",
      "#\r\n",
      "# Train on TPU-8\r\n",
      "\r\n",
      "model {\r\n",
      "  ssd {\r\n",
      "    inplace_batchnorm_update: true\r\n",
      "    freeze_batchnorm: false\r\n",
      "    num_classes: 1\r\n",
      "    add_background_class: false\r\n",
      "    box_coder {\r\n",
      "      faster_rcnn_box_coder {\r\n",
      "        y_scale: 10.0\r\n",
      "        x_scale: 10.0\r\n",
      "        height_scale: 5.0\r\n",
      "        width_scale: 5.0\r\n",
      "      }\r\n",
      "    }\r\n",
      "    matcher {\r\n",
      "      argmax_matcher {\r\n",
      "        matched_threshold: 0.5\r\n",
      "        unmatched_threshold: 0.5\r\n",
      "        ignore_thresholds: false\r\n",
      "        negatives_lower_than_unmatched: true\r\n",
      "        force_match_for_each_row: true\r\n",
      "        use_matmul_gather: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    similarity_calculator {\r\n",
      "      iou_similarity {\r\n",
      "      }\r\n",
      "    }\r\n",
      "    encode_background_as_zeros: true\r\n",
      "    anchor_generator {\r\n",
      "      multiscale_anchor_generator {\r\n",
      "        min_level: 3\r\n",
      "        max_level: 7\r\n",
      "        anchor_scale: 4.0\r\n",
      "        aspect_ratios: [1.0, 2.0, 0.5]\r\n",
      "        scales_per_octave: 3\r\n",
      "      }\r\n",
      "    }\r\n",
      "    image_resizer {\r\n",
      "      keep_aspect_ratio_resizer {\r\n",
      "        min_dimension: 512\r\n",
      "        max_dimension: 512\r\n",
      "        pad_to_max_dimension: true\r\n",
      "        }\r\n",
      "    }\r\n",
      "    box_predictor {\r\n",
      "      weight_shared_convolutional_box_predictor {\r\n",
      "        depth: 64\r\n",
      "        class_prediction_bias_init: -4.6\r\n",
      "        conv_hyperparams {\r\n",
      "          force_use_bias: true\r\n",
      "          activation: SWISH\r\n",
      "          regularizer {\r\n",
      "            l2_regularizer {\r\n",
      "              weight: 0.00004\r\n",
      "            }\r\n",
      "          }\r\n",
      "          initializer {\r\n",
      "            random_normal_initializer {\r\n",
      "              stddev: 0.01\r\n",
      "              mean: 0.0\r\n",
      "            }\r\n",
      "          }\r\n",
      "          batch_norm {\r\n",
      "            scale: true\r\n",
      "            decay: 0.99\r\n",
      "            epsilon: 0.001\r\n",
      "          }\r\n",
      "        }\r\n",
      "        num_layers_before_predictor: 3\r\n",
      "        kernel_size: 3\r\n",
      "        use_depthwise: true\r\n",
      "      }\r\n",
      "    }\r\n",
      "    feature_extractor {\r\n",
      "      type: 'ssd_efficientnet-b0_bifpn_keras'\r\n",
      "      bifpn {\r\n",
      "        min_level: 3\r\n",
      "        max_level: 7\r\n",
      "        num_iterations: 3\r\n",
      "        num_filters: 64\r\n",
      "      }\r\n",
      "      conv_hyperparams {\r\n",
      "        force_use_bias: true\r\n",
      "        activation: SWISH\r\n",
      "        regularizer {\r\n",
      "          l2_regularizer {\r\n",
      "            weight: 0.00004\r\n",
      "          }\r\n",
      "        }\r\n",
      "        initializer {\r\n",
      "          truncated_normal_initializer {\r\n",
      "            stddev: 0.03\r\n",
      "            mean: 0.0\r\n",
      "          }\r\n",
      "        }\r\n",
      "        batch_norm {\r\n",
      "          scale: true,\r\n",
      "          decay: 0.99,\r\n",
      "          epsilon: 0.001,\r\n",
      "        }\r\n",
      "      }\r\n",
      "    }\r\n",
      "    loss {\r\n",
      "      classification_loss {\r\n",
      "        weighted_sigmoid_focal {\r\n",
      "          alpha: 0.25\r\n",
      "          gamma: 1.5\r\n",
      "        }\r\n",
      "      }\r\n",
      "      localization_loss {\r\n",
      "        weighted_smooth_l1 {\r\n",
      "        }\r\n",
      "      }\r\n",
      "      classification_weight: 1.0\r\n",
      "      localization_weight: 1.0\r\n",
      "    }\r\n",
      "    normalize_loss_by_num_matches: true\r\n",
      "    normalize_loc_loss_by_codesize: true\r\n",
      "    post_processing {\r\n",
      "      batch_non_max_suppression {\r\n",
      "        score_threshold: 1e-8\r\n",
      "        iou_threshold: 0.5\r\n",
      "        max_detections_per_class: 100\r\n",
      "        max_total_detections: 100\r\n",
      "      }\r\n",
      "      score_converter: SIGMOID\r\n",
      "    }\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "train_config: {\r\n",
      "  fine_tune_checkpoint: \"/tf/models/research/deploy/efficientdet_d0_coco17_tpu-32/checkpoint/ckpt-0\"\r\n",
      "  fine_tune_checkpoint_version: V2\r\n",
      "  fine_tune_checkpoint_type: \"detection\"\r\n",
      "  batch_size: 18\r\n",
      "  sync_replicas: true\r\n",
      "  startup_delay_steps: 0\r\n",
      "  replicas_to_aggregate: 8\r\n",
      "  use_bfloat16: true\r\n",
      "  num_steps: 5000\r\n",
      "  data_augmentation_options {\r\n",
      " random_distort_color: { \r\n",
      " } \r\n",
      "}\r\n",
      "\r\n",
      "data_augmentation_options {\r\n",
      " random_horizontal_flip: { \r\n",
      " } \r\n",
      "}\r\n",
      "\r\n",
      "data_augmentation_options {\r\n",
      " random_vertical_flip: { \r\n",
      " } \r\n",
      "}\r\n",
      "\r\n",
      "data_augmentation_options {\r\n",
      " random_rotation90: { \r\n",
      " } \r\n",
      "}\r\n",
      "\r\n",
      "data_augmentation_options {\r\n",
      " random_jitter_boxes: { \r\n",
      " } \r\n",
      "}\r\n",
      "\r\n",
      "data_augmentation_options {\r\n",
      " random_crop_image {\r\n",
      "\tmin_object_covered: 1.0\r\n",
      "\tmin_aspect_ratio: 0.75\r\n",
      "\tmax_aspect_ratio: 1.5\r\n",
      "\tmin_area: 0.25\r\n",
      "\tmax_area: 0.875\r\n",
      "\toverlap_thresh: 0.5\r\n",
      "\trandom_coef: 0.125\r\n",
      "}\r\n",
      "}\r\n",
      "\r\n",
      "\r\n",
      "  optimizer {\r\n",
      "    momentum_optimizer: {\r\n",
      "      learning_rate: {\r\n",
      "        cosine_decay_learning_rate {\r\n",
      "          learning_rate_base: 8e-2\r\n",
      "          total_steps: 5000\r\n",
      "          warmup_learning_rate: 0.001\r\n",
      "          warmup_steps: 2500\r\n",
      "        }\r\n",
      "      }\r\n",
      "      momentum_optimizer_value: 0.9\r\n",
      "    }\r\n",
      "    use_moving_average: false\r\n",
      "  }\r\n",
      "  max_number_of_boxes: 100\r\n",
      "  unpad_groundtruth_tensors: false\r\n",
      "}\r\n",
      "\r\n",
      "train_input_reader: {\r\n",
      "  label_map_path: \"/tf/dataset-export/lb-400images-efficientdet-d0-augment-model/label_map.pbtxt\"\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/tf/dataset-export/lb-400images-efficientdet-d0-augment-model/train/tf.records\"\r\n",
      "  }\r\n",
      "}\r\n",
      "\r\n",
      "eval_config: {\r\n",
      "  metrics_set: \"coco_detection_metrics\"\r\n",
      "  use_moving_averages: false\r\n",
      "  batch_size: 18;\r\n",
      "}\r\n",
      "\r\n",
      "eval_input_reader: {\r\n",
      "  label_map_path: \"/tf/dataset-export/lb-400images-efficientdet-d0-augment-model/label_map.pbtxt\"\r\n",
      "  shuffle: false\r\n",
      "  num_epochs: 1\r\n",
      "  tf_record_input_reader {\r\n",
      "    input_path: \"/tf/dataset-export/lb-400images-efficientdet-d0-augment-model/val/tf.records\"\r\n",
      "  }\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "%cat /tf/models/research/deploy/pipeline_file.config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Custom TF2 Object Detector\n",
    "\n",
    "This step will launch the TF2 Object Detection training. It can take a while to start-up. \n",
    "If you get an error about not finding the GPU, try shutting down the Jupyter kernel and restarting it.\n",
    "While it is running, it should print out the Current Loss and which Step it is on.\n",
    "\n",
    "* pipeline_file: defined above in writing custom training configuration\n",
    "* model_dir: the location tensorboard logs and saved model checkpoints will save to\n",
    "* num_train_steps: how long to train for\n",
    "* num_eval_steps: perform eval on validation set after this many steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-07-08 20:53:56.154660: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-08 20:53:59.234024: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-07-08 20:53:59.259096: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-08 20:53:59.259998: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-07-08 20:53:59.260066: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-08 20:53:59.264586: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-07-08 20:53:59.264668: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-07-08 20:53:59.265942: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-07-08 20:53:59.266271: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-07-08 20:53:59.267456: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-07-08 20:53:59.268525: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-07-08 20:53:59.268757: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-07-08 20:53:59.268885: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-08 20:53:59.269705: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-08 20:53:59.270442: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-08 20:53:59.270765: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-07-08 20:53:59.271185: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-08 20:53:59.271986: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-07-08 20:53:59.272113: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-08 20:53:59.272913: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-08 20:53:59.273640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-07-08 20:53:59.273696: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-07-08 20:53:59.833997: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-07-08 20:53:59.834052: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-07-08 20:53:59.834078: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-07-08 20:53:59.834369: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-08 20:53:59.835221: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-08 20:53:59.836071: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-07-08 20:53:59.836837: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10661 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\n",
      "WARNING:tensorflow:Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "W0708 20:53:59.839558 139809137821504 mirrored_strategy.py:379] Collective ops is not configured at program startup. Some performance features may not be enabled.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "I0708 20:54:00.073076 139809137821504 mirrored_strategy.py:369] Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO:tensorflow:Maybe overwriting train_steps: 40000\n",
      "I0708 20:54:00.080240 139809137821504 config_util.py:552] Maybe overwriting train_steps: 40000\n",
      "INFO:tensorflow:Maybe overwriting use_bfloat16: False\n",
      "I0708 20:54:00.080397 139809137821504 config_util.py:552] Maybe overwriting use_bfloat16: False\n",
      "I0708 20:54:00.098092 139809137821504 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0708 20:54:00.098223 139809137821504 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0708 20:54:00.098315 139809137821504 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
      "I0708 20:54:00.111051 139809137821504 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.157430 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.162168 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.166090 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.167571 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.176658 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.181722 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.188164 139809137821504 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0708 20:54:00.188306 139809137821504 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.204999 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.206089 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.208090 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "INFO:tensorflow:Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.209198 139809137821504 cross_device_ops.py:621] Reduce to /job:localhost/replica:0/task:0/device:CPU:0 then broadcast to ('/job:localhost/replica:0/task:0/device:CPU:0',).\n",
      "I0708 20:54:00.299303 139809137821504 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0708 20:54:00.299443 139809137821504 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0708 20:54:00.580756 139809137821504 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0708 20:54:00.580913 139809137821504 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0708 20:54:00.862522 139809137821504 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0708 20:54:00.862695 139809137821504 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0708 20:54:01.290074 139809137821504 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0708 20:54:01.290266 139809137821504 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0708 20:54:01.719866 139809137821504 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0708 20:54:01.720074 139809137821504 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0708 20:54:02.316785 139809137821504 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0708 20:54:02.316966 139809137821504 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0708 20:54:02.455372 139809137821504 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0708 20:54:02.510057 139809137821504 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:551: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "W0708 20:54:02.579920 139809137821504 deprecation.py:336] From /usr/local/lib/python3.6/dist-packages/object_detection/model_lib_v2.py:551: StrategyBase.experimental_distribute_datasets_from_function (from tensorflow.python.distribute.distribute_lib) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "rename to distribute_datasets_from_function\n",
      "INFO:tensorflow:Reading unweighted datasets: ['/tf/dataset-export/881images-efficientdet-d0-model/train/tf.records']\n",
      "I0708 20:54:02.583544 139809137821504 dataset_builder.py:163] Reading unweighted datasets: ['/tf/dataset-export/881images-efficientdet-d0-model/train/tf.records']\n",
      "INFO:tensorflow:Reading record datasets for input file: ['/tf/dataset-export/881images-efficientdet-d0-model/train/tf.records']\n",
      "I0708 20:54:02.583787 139809137821504 dataset_builder.py:80] Reading record datasets for input file: ['/tf/dataset-export/881images-efficientdet-d0-model/train/tf.records']\n",
      "INFO:tensorflow:Number of filenames to read: 1\n",
      "I0708 20:54:02.583929 139809137821504 dataset_builder.py:81] Number of filenames to read: 1\n",
      "WARNING:tensorflow:num_readers has been reduced to 1 to match input file shards.\n",
      "W0708 20:54:02.584053 139809137821504 dataset_builder.py:88] num_readers has been reduced to 1 to match input file shards.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "W0708 20:54:02.586497 139809137821504 deprecation.py:336] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:105: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_deterministic`.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n",
      "W0708 20:54:02.613253 139809137821504 deprecation.py:336] From /usr/local/lib/python3.6/dist-packages/object_detection/builders/dataset_builder.py:237: DatasetV1.map_with_legacy_function (from tensorflow.python.data.ops.dataset_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map()\n"
     ]
    }
   ],
   "source": [
    "# 2:48 PM ET Tuesday, May 25, 2021\n",
    "!python /tf/models/research/object_detection/model_main_tf2.py \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --model_dir={model_dir} \\\n",
    "    --alsologtostderr \\\n",
    "    --num_train_steps={num_steps} \\\n",
    "    --sample_1_of_n_eval_examples=1 \\\n",
    "    --num_eval_steps={num_eval_steps} "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate trained model\n",
    "After the model has finished training, try running it against some data to see if it atleast works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import io, os, glob\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image_into_numpy_array(path):\n",
    "\n",
    "    \"\"\"Load an image from file into a numpy array.\n",
    "\n",
    "    Puts image into numpy array to feed into tensorflow graph.\n",
    "    Note that by convention we put it into a numpy array with shape\n",
    "    (height, width, channels), where channels=3 for RGB.\n",
    "\n",
    "    Args:\n",
    "    path: the file path to the image\n",
    "\n",
    "    Returns:\n",
    "    uint8 numpy array with shape (img_height, img_width, 3)\n",
    "    \"\"\"\n",
    "    img_data = tf.io.gfile.GFile(path, 'rb').read()\n",
    "    image = Image.open(BytesIO(img_data))\n",
    "    (im_width, im_height) = image.size\n",
    "    return np.array(image.getdata()).reshape((im_height, im_width, 3)).astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%ls {model_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model from a training checkpoint\n",
    "Select a checkpoint index from above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# generally you want to put the last ckpt index from training in here\n",
    "checkpoint_index=41\n",
    "\n",
    "# recover our saved model\n",
    "pipeline_config = pipeline_file\n",
    "\n",
    "checkpoint = model_dir + \"ckpt-\" + str(checkpoint_index)\n",
    "configs = config_util.get_configs_from_pipeline_file(pipeline_config)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "# Restore checkpoint\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(checkpoint)).expect_partial()\n",
    "\n",
    "\n",
    "def get_model_detection_function(model):\n",
    "  \"\"\"Get a tf.function for detection.\"\"\"\n",
    "\n",
    "  @tf.function\n",
    "  def detect_fn(image):\n",
    "    \"\"\"Detect objects in image.\"\"\"\n",
    "\n",
    "    image, shapes = model.preprocess(image)\n",
    "    prediction_dict = model.predict(image, shapes)\n",
    "    detections = model.postprocess(prediction_dict, shapes)\n",
    "\n",
    "    return detections, prediction_dict, tf.reshape(shapes, [-1])\n",
    "\n",
    "  return detect_fn\n",
    "\n",
    "detect_fn = get_model_detection_function(detection_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map labels for inference decoding\n",
    "label_map_path = configs['eval_input_config'].label_map_path\n",
    "label_map = label_map_util.load_labelmap(label_map_path)\n",
    "categories = label_map_util.convert_label_map_to_categories(\n",
    "    label_map,\n",
    "    max_num_classes=label_map_util.get_max_label_map_index(label_map),\n",
    "    use_display_name=True)\n",
    "category_index = label_map_util.create_category_index(categories)\n",
    "label_map_dict = label_map_util.get_label_map_dict(label_map, use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run detector on test image\n",
    "#it takes a little longer on the first run and then runs at normal speed. \n",
    "import random\n",
    "\n",
    "TEST_IMAGE_PATHS = glob.glob('/tf/media/capture-5-13/Textron Aviation Inc 680A/*.jpg') #/tf/dataset-export/pet/images/keeshond_171.jpg') #'/tf/testing/Dassault Aviation FALCON 2000/*.jpg')\n",
    "image_path = random.choice(TEST_IMAGE_PATHS)\n",
    "image_np = load_image_into_numpy_array(image_path)\n",
    "\n",
    "input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "\n",
    "detections, predictions_dict, shapes = detect_fn(input_tensor)\n",
    "\n",
    "\n",
    "print(detections['detection_scores'])\n",
    "label_id_offset = 1 # Depending on whether your LabelMap starts at 0 or 1\n",
    "image_np_with_detections = image_np.copy()\n",
    "\n",
    "viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "      image_np_with_detections,\n",
    "      detections['detection_boxes'][0].numpy(),\n",
    "      (detections['detection_classes'][0].numpy() + label_id_offset).astype(int),\n",
    "      detections['detection_scores'][0].numpy(),\n",
    "      category_index,\n",
    "      use_normalized_coordinates=True,\n",
    "      max_boxes_to_draw=200,\n",
    "      min_score_thresh=.2,\n",
    "      agnostic_mode=False,\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(20,25))\n",
    "plt.imshow(image_np_with_detections)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export the model\n",
    "When you have a working model, use the TF2 Object Detection API to export it to a saved model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a Saved Model that uses Image Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tensor_model_export_dir = model_export_dir + \"image_tensor_saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tf/model-export/lb-400images-efficientdet-d0-augment-model/image_tensor_saved_model\n"
     ]
    }
   ],
   "source": [
    "print(image_tensor_model_export_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2021-06-28 23:00:37.233618: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-28 23:00:39.839076: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcuda.so.1\n",
      "2021-06-28 23:00:39.864436: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-28 23:00:39.865310: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-06-28 23:00:39.865362: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-28 23:00:39.869447: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublas.so.11\n",
      "2021-06-28 23:00:39.869533: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcublasLt.so.11\n",
      "2021-06-28 23:00:39.870937: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcufft.so.10\n",
      "2021-06-28 23:00:39.871318: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcurand.so.10\n",
      "2021-06-28 23:00:39.872613: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusolver.so.11\n",
      "2021-06-28 23:00:39.873689: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcusparse.so.11\n",
      "2021-06-28 23:00:39.873938: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudnn.so.8\n",
      "2021-06-28 23:00:39.874103: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-28 23:00:39.874960: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-28 23:00:39.875740: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-06-28 23:00:39.876140: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-06-28 23:00:39.876588: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-28 23:00:39.877376: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1733] Found device 0 with properties: \n",
      "pciBusID: 0000:00:1e.0 name: Tesla K80 computeCapability: 3.7\n",
      "coreClock: 0.8235GHz coreCount: 13 deviceMemorySize: 11.17GiB deviceMemoryBandwidth: 223.96GiB/s\n",
      "2021-06-28 23:00:39.877497: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-28 23:00:39.878292: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-28 23:00:39.879020: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1871] Adding visible gpu devices: 0\n",
      "2021-06-28 23:00:39.879080: I tensorflow/stream_executor/platform/default/dso_loader.cc:53] Successfully opened dynamic library libcudart.so.11.0\n",
      "2021-06-28 23:00:40.521033: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1258] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2021-06-28 23:00:40.521120: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1264]      0 \n",
      "2021-06-28 23:00:40.521143: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1277] 0:   N \n",
      "2021-06-28 23:00:40.521465: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-28 23:00:40.522340: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-28 23:00:40.523146: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:937] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2021-06-28 23:00:40.523906: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1418] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 10661 MB memory) -> physical GPU (device: 0, name: Tesla K80, pci bus id: 0000:00:1e.0, compute capability: 3.7)\n",
      "I0628 23:00:40.785022 140532255090496 ssd_efficientnet_bifpn_feature_extractor.py:143] EfficientDet EfficientNet backbone version: efficientnet-b0\n",
      "I0628 23:00:40.785330 140532255090496 ssd_efficientnet_bifpn_feature_extractor.py:144] EfficientDet BiFPN num filters: 64\n",
      "I0628 23:00:40.785445 140532255090496 ssd_efficientnet_bifpn_feature_extractor.py:146] EfficientDet BiFPN num iterations: 3\n",
      "I0628 23:00:40.792782 140532255090496 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0628 23:00:40.825772 140532255090496 efficientnet_model.py:147] round_filter input=32 output=32\n",
      "I0628 23:00:40.825912 140532255090496 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0628 23:00:40.894950 140532255090496 efficientnet_model.py:147] round_filter input=16 output=16\n",
      "I0628 23:00:40.895127 140532255090496 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0628 23:00:41.066718 140532255090496 efficientnet_model.py:147] round_filter input=24 output=24\n",
      "I0628 23:00:41.066934 140532255090496 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0628 23:00:41.239912 140532255090496 efficientnet_model.py:147] round_filter input=40 output=40\n",
      "I0628 23:00:41.240132 140532255090496 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0628 23:00:41.503206 140532255090496 efficientnet_model.py:147] round_filter input=80 output=80\n",
      "I0628 23:00:41.503429 140532255090496 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0628 23:00:41.763689 140532255090496 efficientnet_model.py:147] round_filter input=112 output=112\n",
      "I0628 23:00:41.763906 140532255090496 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0628 23:00:42.249581 140532255090496 efficientnet_model.py:147] round_filter input=192 output=192\n",
      "I0628 23:00:42.249801 140532255090496 efficientnet_model.py:147] round_filter input=320 output=320\n",
      "I0628 23:00:42.333547 140532255090496 efficientnet_model.py:147] round_filter input=1280 output=1280\n",
      "I0628 23:00:42.368739 140532255090496 efficientnet_model.py:458] Building model efficientnet with params ModelConfig(width_coefficient=1.0, depth_coefficient=1.0, resolution=224, dropout_rate=0.2, blocks=(BlockConfig(input_filters=32, output_filters=16, kernel_size=3, num_repeat=1, expand_ratio=1, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=16, output_filters=24, kernel_size=3, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=24, output_filters=40, kernel_size=5, num_repeat=2, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=40, output_filters=80, kernel_size=3, num_repeat=3, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=80, output_filters=112, kernel_size=5, num_repeat=3, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=112, output_filters=192, kernel_size=5, num_repeat=4, expand_ratio=6, strides=(2, 2), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise'), BlockConfig(input_filters=192, output_filters=320, kernel_size=3, num_repeat=1, expand_ratio=6, strides=(1, 1), se_ratio=0.25, id_skip=True, fused_conv=False, conv_type='depthwise')), stem_base_filters=32, top_base_filters=1280, activation='simple_swish', batch_norm='default', bn_momentum=0.99, bn_epsilon=0.001, weight_decay=5e-06, drop_connect_rate=0.2, depth_divisor=8, min_depth=None, use_se=True, input_channels=3, num_classes=1000, model_name='efficientnet', rescale_input=False, data_format='channels_last', dtype='float32')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "W0628 23:00:44.854540 140532255090496 deprecation.py:601] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/autograph/impl/api.py:463: calling map_fn_v2 (from tensorflow.python.ops.map_fn) with back_prop=False is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "back_prop=False is deprecated. Consider using tf.stop_gradient instead.\n",
      "Instead of:\n",
      "results = tf.map_fn(fn, elems, back_prop=False)\n",
      "Use:\n",
      "results = tf.nest.map_structure(tf.stop_gradient, tf.map_fn(fn, elems))\n",
      "WARNING:tensorflow:Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fcfb045b668>, because it is not built.\n",
      "W0628 23:01:06.566806 140532255090496 save_impl.py:77] Skipping full serialization of Keras layer <object_detection.meta_architectures.ssd_meta_arch.SSDMetaArch object at 0x7fcfb045b668>, because it is not built.\n",
      "2021-06-28 23:01:35.912511: W tensorflow/python/util/util.cc:348] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "W0628 23:02:13.607227 140532255090496 save.py:243] Found untraced functions such as WeightSharedConvolutionalBoxPredictor_layer_call_fn, WeightSharedConvolutionalBoxPredictor_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxHead_layer_call_fn, WeightSharedConvolutionalBoxHead_layer_call_and_return_conditional_losses, WeightSharedConvolutionalBoxPredictor_layer_call_fn while saving (showing 5 of 795). These functions will not be directly callable after loading.\n",
      "/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/utils/generic_utils.py:497: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  category=CustomMaskWarning)\n",
      "WARNING:tensorflow:FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "W0628 23:02:25.556529 140532255090496 save.py:1240] FOR KERAS USERS: The object that you are saving contains one or more Keras models or layers. If you are loading the SavedModel with `tf.keras.models.load_model`, continue reading (otherwise, you may ignore the following instructions). Please change your code to save with `tf.keras.models.save_model` or `model.save`, and confirm that the file \"keras.metadata\" exists in the export directory. In the future, Keras will only load the SavedModels that have this file. In other words, `tf.saved_model.save` will no longer write SavedModels that can be recovered as Keras models (this will apply in TF 2.5).\n",
      "\n",
      "FOR DEVS: If you are overwriting _tracking_metadata in your class, this property has been used to save metadata in the SavedModel. The metadta field will be deprecated soon, so please move the metadata to a different file.\n",
      "INFO:tensorflow:Assets written to: /tf/model-export/lb-400images-efficientdet-d0-augment-model/image_tensor_saved_model/saved_model/assets\n",
      "I0628 23:02:26.628620 140532255090496 builder_impl.py:775] Assets written to: /tf/model-export/lb-400images-efficientdet-d0-augment-model/image_tensor_saved_model/saved_model/assets\n",
      "INFO:tensorflow:Writing pipeline config file to /tf/model-export/lb-400images-efficientdet-d0-augment-model/image_tensor_saved_model/pipeline.config\n",
      "I0628 23:02:28.890484 140532255090496 config_util.py:254] Writing pipeline config file to /tf/model-export/lb-400images-efficientdet-d0-augment-model/image_tensor_saved_model/pipeline.config\n"
     ]
    }
   ],
   "source": [
    "!python /tf/models/research/object_detection/exporter_main_v2.py \\\n",
    "    --input_type image_tensor \\\n",
    "    --trained_checkpoint_dir={model_dir} \\\n",
    "    --pipeline_config_path={pipeline_file} \\\n",
    "    --output_directory {image_tensor_model_export_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a Saved Model that uses TF Examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ignore for now - we do not need to use the TF Example approach.\n",
    "\n",
    "#tf_example_model_export_dir = model_export_dir + \"tf_example_saved_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!python /tf/models/research/object_detection/exporter_main_v2.py \\\n",
    "#    --input_type=tf_example \\\n",
    "#    --trained_checkpoint_dir={model_dir} \\\n",
    "#    --pipeline_config_path={pipeline_file} \\\n",
    "#    --output_directory {tf_example_model_export_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a TFLite compatible model\n",
    "Remeber that only Detection models that use SSDs are supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python /tf/models/research/object_detection/export_tflite_graph_tf2.py \\\n",
    "  --pipeline_config_path={pipeline_file} \\\n",
    "  --trained_checkpoint_dir={model_dir} \\\n",
    "  --output_directory={model_export_dir}tflite-compatible\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I think we skip this step...\n",
    "\n",
    "#! tflite_convert \\\n",
    "#    --saved_model_dir=\"{model_export_dir}tflite-compatible/saved_model\" \\\n",
    "#    --output_file=\"{model_export_dir}output.tflite\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://github.com/tensorflow/models/issues/9033#issuecomment-706573546\n",
    "import cv2\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "train_images = []\n",
    "\n",
    "def representative_data_gen():\n",
    "    path = '/tf/testing/Airbus A319-115'\n",
    "\n",
    "    dataset_list = tf.data.Dataset.list_files(path + '/*.jpg')\n",
    "    for i in range(100):\n",
    "        image = next(iter(dataset_list))\n",
    "        image = tf.io.read_file(image)\n",
    "        image = tf.io.decode_jpeg(image, channels=3)\n",
    "        image = tf.image.resize(image, [300, 300])\n",
    "        image = tf.cast(image / 255., tf.float32)\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        yield [image]\n",
    "\n",
    "\n",
    "converter = tf.lite.TFLiteConverter.from_saved_model(model_export_dir+\"tflite-compatible/saved_model\")\n",
    "converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8,\n",
    "                                       tf.lite.OpsSet.TFLITE_BUILTINS]\n",
    "#converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
    "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8, tf.lite.OpsSet.SELECT_TF_OPS]\n",
    "#converter.inference_input_type = tf.int8\n",
    "#converter.inference_output_type = tf.int8\n",
    "converter.representative_dataset = representative_data_gen\n",
    "# Ensure that if any ops can't be quantized, the converter throws an error\n",
    "#converter.target_spec.supported_ops = [tf.lite.OpsSet.TFLITE_BUILTINS_INT8]\n",
    "# Set the input and output tensors to uint8 (APIs added in r2.3)\n",
    "#converter.inference_input_type = tf.uint8\n",
    "#converter.inference_output_type = tf.uint8\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "# Save the model.\n",
    "with open(model_export_dir+'model.tflite', 'wb') as f:\n",
    "  f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl https://packages.cloud.google.com/apt/doc/apt-key.gpg | apt-key add -\n",
    "!echo \"deb https://packages.cloud.google.com/apt coral-edgetpu-stable main\" | tee /etc/apt/sources.list.d/coral-edgetpu.list\n",
    "!apt-get update\n",
    "!apt-get -y install edgetpu-compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!edgetpu_compiler -s {model_export_dir}model.tflite -o {model_export_dir}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export a TensorJS compatible model\n",
    "From: https://www.tensorflow.org/js/tutorials/conversion/import_saved_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflowjs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! tensorflowjs_converter \\\n",
    "    --input_format=tf_saved_model \\\n",
    "    {model_export_dir}image_tensor_saved_model/saved_model \\\n",
    "    {model_export_dir}web_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!saved_model_cli show --dir /tf/models/research/deploy/ssd_mobilenet_v2_320x320_coco17_tpu-8/saved_model --all"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
