{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import os\n",
    "import random\n",
    "import io\n",
    "import imageio\n",
    "import scipy.misc\n",
    "import numpy as np\n",
    "from six import BytesIO\n",
    "from PIL import Image, ImageDraw, ImageFont\n",
    "from IPython.display import display, Javascript\n",
    "from IPython.display import Image as IPyImage\n",
    "\n",
    "import tensorflow as tf\n",
    "from object_detection.protos.string_int_label_map_pb2 import StringIntLabelMap, StringIntLabelMapItem\n",
    "from google.protobuf import text_format\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_name = \"plane-dataset\" # The name of the V51 dataset that will be used\n",
    "training_name = \"simple_model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The different directories and filenames to use\n",
    "train_record_fname = \"/tf/dataset-export/\" + training_name + \"/train/tf.records\"\n",
    "val_record_fname = \"/tf/dataset-export/\" + training_name + \"/val/tf.records\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_image_dataset = tf.data.TFRecordDataset(train_record_fname)\n",
    "image_feature_description = {\n",
    "    # Image dimensions\n",
    "    \"image/height\": tf.io.FixedLenFeature([], tf.int64),\n",
    "    \"image/width\": tf.io.FixedLenFeature([], tf.int64),\n",
    "\n",
    "    # Image filename is used for both of these when writing\n",
    "    \"image/filename\": tf.io.FixedLenFeature([], tf.string),\n",
    "    \"image/source_id\": tf.io.FixedLenFeature([], tf.string),\n",
    "\n",
    "    # Encoded image bytes\n",
    "    \"image/encoded\": tf.io.FixedLenFeature([], tf.string),\n",
    "\n",
    "    # Image format, either `jpeg` or `png`\n",
    "    \"image/format\": tf.io.FixedLenFeature([], tf.string),\n",
    "\n",
    "    # Normalized bounding box coordinates in `[0, 1]`\n",
    "    \"image/object/bbox/xmin\": tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    \"image/object/bbox/xmax\": tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    \"image/object/bbox/ymin\": tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "    \"image/object/bbox/ymax\": tf.io.FixedLenSequenceFeature([], tf.float32, allow_missing=True),\n",
    "\n",
    "    # Class label string\n",
    "    \"image/object/class/text\": tf.io.FixedLenSequenceFeature([], tf.string, allow_missing=True),\n",
    "\n",
    "    # Integer class ID\n",
    "    \"image/object/class/label\": tf.io.FixedLenSequenceFeature([], tf.int64, allow_missing=True)\n",
    "}\n",
    "def _parse_image_function(example_proto):\n",
    "  # Parse the input tf.train.Example proto using the dictionary above.\n",
    "  return tf.io.parse_single_example(example_proto, image_feature_description)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<MapDataset shapes: {image/encoded: (), image/filename: (), image/format: (), image/height: (), image/object/bbox/xmax: (None,), image/object/bbox/xmin: (None,), image/object/bbox/ymax: (None,), image/object/bbox/ymin: (None,), image/object/class/label: (None,), image/object/class/text: (None,), image/source_id: (), image/width: ()}, types: {image/encoded: tf.string, image/filename: tf.string, image/format: tf.string, image/height: tf.int64, image/object/bbox/xmax: tf.float32, image/object/bbox/xmin: tf.float32, image/object/bbox/ymax: tf.float32, image/object/bbox/ymin: tf.float32, image/object/class/label: tf.int64, image/object/class/text: tf.string, image/source_id: tf.string, image/width: tf.int64}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parsed_image_dataset = raw_image_dataset.map(_parse_image_function)\n",
    "parsed_image_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'module' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-63a4ef3a57ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mimage_features\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mparsed_image_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m   \u001b[0mimage_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_features\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'image/encoded'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m   \u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimage_raw\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: 'module' object is not callable"
     ]
    }
   ],
   "source": [
    "for image_features in parsed_image_dataset:\n",
    "  image_raw = image_features['image/encoded'].numpy()\n",
    "  display(Image(data=image_raw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
